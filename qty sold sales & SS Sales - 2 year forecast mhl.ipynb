{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": [
        "%pyspark\n",
        "\n",
        "from pyspark.sql.types import *\n",
        "from pyspark.sql.functions import *\n",
        "from pyspark.sql import *\n",
        "from pyspark.sql import Row\n",
        "import datetime\n",
        "from datetime import date\n",
        "\n",
        "#from fin_utils import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": [
        "%pyspark\n",
        "\n",
        "# Read sales details (source) table name\n",
        "sales_details_db_name = \"dds_prod\"\n",
        "sales_details_table_name = \"dds_prod.invoice_cshdet\"\n",
        "\n",
        "# Read sales agg table storage location (target)\n",
        "sales_agg_sales_transaction_daily_s3path = \"s3://aap-dpdm-prod/dpdm.db/agg_sales_transactions_daily\"\n",
        "\n",
        "# Read sales agg table storage location (target)\n",
        "sales_agg_sales_store_sku_daily_db_name = \"dpdm_prod\"\n",
        "sales_agg_sales_store_sku_daily_table_name = \"dpdm_prod.agg_sales_store_sku_daily\"\n",
        "\n",
        "sales_agg_sales_store_sku_daily_s3path = \"s3://aap-dpdm-prod/dpdm.db/agg_sales_store_sku_daily\"\n",
        "\n",
        "sku_rolling_sales_db_name = \"dpdm_prod\"\n",
        "sku_rolling_sales_table_name = \"dpdm_prod.sku_rolling_sales\"\n",
        "\n",
        "sales_agg_sales_by_sku_s3path = \"s3://aap-dpdm-prod/dpdm.db/sku_rolling_sales\"\n",
        "\n",
        "# Read store_master (master table) table\n",
        "store_master_db_name = \"dds_prod\"\n",
        "store_master_table_name = \"dds_prod.store_master\"\n",
        "\n",
        "# Read sku_master (master table) table\n",
        "sku_master_db_name = \"dds_prod\"\n",
        "sku_master_table_name = \"dds_prod.sku_master\"\n",
        "\n",
        "# Read calendar hierarchy table\n",
        "cal_hierarchy_db_name = \"dds_prod\"\n",
        "cal_hierarchy_table_name = \"dds_prod.cal_hierarchy\"\n",
        "\n",
        "# Read cluster_definition (master) table\n",
        "clus_def_db_name = \"dds_prod\"\n",
        "clus_def_table_name = \"dds_prod.cluster_definition\"\n",
        "\n",
        "# Read sku_base_product_grp (master) table\n",
        "sku_prodgrp_db_name = \"dpdm_prod\"\n",
        "sku_prodgrp_table_name = \"dpdm_prod.sku_base_product_group\"\n",
        "\n",
        "# Read sku_data (master) table\n",
        "sku_data_db_name = \"dpdm_prod\"\n",
        "sku_data_table_name = \"dpdm_prod.sku_data\"\n",
        "\n",
        "# Read sku_part_type (master) table\n",
        "sku_part_type_db_name =\"dds_prod\"\n",
        "sku_part_type_table_name = \"dds_prod.sku_part_type\"\n",
        "\n",
        "# Read agg sales storage location (target)\n",
        "agg_sales_transactions_daily_db_name = \"dpdm_prod\"\n",
        "agg_sales_transactions_daily_table_name = \"dpdm_prod.agg_sales_transactions_daily\"\n",
        "\n",
        "# Read store sku rolling sales (source) table name\n",
        "store_sku_rolling_sales_db_name = \"dpdm_prod\"\n",
        "store_sku_rolling_sales_table_name = \"dpdm_prod.store_sku_rolling_sales\"\n",
        "\n",
        "store_sku_rolling_sales_s3path = \"s3://aap-dpdm-prod/dpdm.db/cq_store_sku_rolling_sales\"\n",
        "\n",
        "store_sales_by_period_db_name = \"dpdm_prod\"\n",
        "store_sales_by_period_table_name = \"dpdm_prod.store_sales_by_period\"\n",
        "\n",
        "store_sales_by_period_s3path = \"s3://aap-dpdm-prod/dpdm.db/store_sales_by_period\"\n",
        "\n",
        "daily_sales_store_sku = \"dds_prod.daily_sales\"\n",
        "\n",
        "ad_promo_monthly_sales = \"dpdm_prod.ad_promo_monthly_sales_by_bpg\"\n",
        "\n",
        "ad_promo_monthly_sales_by_store_sku = \"dpdm_prod.ad_promo_sales_by_str_sku\"\n",
        "\n",
        "agg_sales_ad_promo_monthly_sku_s3path = \"s3://aap-dpdm-prod/dpdm.db/ad_promo_monthly_sales_merch\"\n",
        "agg_sales_ad_promo_monthly_store_sku_s3path = \"s3://aap-dpdm-prod/dpdm.db/ad_promo_monthly_sales_by_store_sku\"\n",
        "\n",
        "agg_sales_daily_store_sku_s3path = \"s3://aap-data-exploration/tmp_daily_sales/prod\"\n",
        "\n",
        "agg_sales_weekly_store_sku_s3path = \"s3://aap-data-exploration/tmp_weekly_sales/prod\"\n",
        "\n",
        "agg_sales_weekly_store_sku_by_bpg_s3path = \"s3://aap-dpdm-dev/dpdm.db/cq_weekly_sales_by_bpg\"\n",
        "\n",
        "agg_sales_weekly_store_sku = \"dds_prod.weekly_sales\"\n",
        "\n",
        "agg_sales_weekly_sku_s3path = \"s3://aap-data-exploration/tmp_weekly_sales_by_sku/prod\"\n",
        "\n",
        "job_metrics_db_name = \"dpdm_prod\"\n",
        "job_metrics_table_name = \"dpdm_prod.dp_job_metrics\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": [
        "%pyspark\n",
        "\n",
        "pc_data = [\n",
        "    Row(sequence_id=1, cal_year=2000, cal_period=1, start_date=date(2000, 1, 2), end_date=date(2000, 1, 29),days_in_period=28)\n",
        "    , Row(sequence_id=2, cal_year=2000, cal_period=2, start_date=date(2000, 1, 30), end_date=date(2000, 2, 26),days_in_period=28)\n",
        "    , Row(sequence_id=3, cal_year=2000, cal_period=3, start_date=date(2000, 2, 27), end_date=date(2000, 3, 25), days_in_period=28)\n",
        "    , Row(sequence_id=4, cal_year=2000, cal_period=4, start_date=date(2000, 3, 26), end_date=date(2000, 4, 22), days_in_period=28)\n",
        "    , Row(sequence_id=5, cal_year=2000, cal_period=5, start_date=date(2000, 4, 23), end_date=date(2000, 5, 20), days_in_period=28)\n",
        "    , Row(sequence_id=6, cal_year=2000, cal_period=6, start_date=date(2000, 5, 21), end_date=date(2000, 6, 17), days_in_period=28)\n",
        "    , Row(sequence_id=7, cal_year=2000, cal_period=7, start_date=date(2000, 6, 18), end_date=date(2000, 7, 15), days_in_period=28)\n",
        "    , Row(sequence_id=8, cal_year=2000, cal_period=8, start_date=date(2000, 7, 16), end_date=date(2000, 8, 12), days_in_period=28)\n",
        "    , Row(sequence_id=9, cal_year=2000, cal_period=9, start_date=date(2000, 8, 13), end_date=date(2000, 9, 9), days_in_period=28)\n",
        "    , Row(sequence_id=10, cal_year=2000, cal_period=10, start_date=date(2000, 9, 10), end_date=date(2000, 10, 7), days_in_period=28)\n",
        "    , Row(sequence_id=11, cal_year=2000, cal_period=11, start_date=date(2000, 10, 8), end_date=date(2000, 11, 4), days_in_period=28)\n",
        "    , Row(sequence_id=12, cal_year=2000, cal_period=12, start_date=date(2000, 11, 5), end_date=date(2000, 12, 2), days_in_period=28)\n",
        "    , Row(sequence_id=13, cal_year=2000, cal_period=13, start_date=date(2000, 12, 3), end_date=date(2000, 12, 30), days_in_period=28)\n",
        "    , Row(sequence_id=14, cal_year=2001, cal_period=1, start_date=date(2000, 12, 31), end_date=date(2001, 1, 27), days_in_period=28)\n",
        "    , Row(sequence_id=15, cal_year=2001, cal_period=2, start_date=date(2001, 1, 28), end_date=date(2001, 2, 24), days_in_period=28)\n",
        "    , Row(sequence_id=16, cal_year=2001, cal_period=3, start_date=date(2001, 2, 25), end_date=date(2001, 3, 24), days_in_period=28)\n",
        "    , Row(sequence_id=17, cal_year=2001, cal_period=4, start_date=date(2001, 3, 25), end_date=date(2001, 4, 21), days_in_period=28)\n",
        "    , Row(sequence_id=18, cal_year=2001, cal_period=5, start_date=date(2001, 4, 22), end_date=date(2001, 5, 19), days_in_period=28)\n",
        "    , Row(sequence_id=19, cal_year=2001, cal_period=6, start_date=date(2001, 5, 20), end_date=date(2001, 6, 16), days_in_period=28)\n",
        "    , Row(sequence_id=20, cal_year=2001, cal_period=7, start_date=date(2001, 6, 17), end_date=date(2001, 7, 14), days_in_period=28)\n",
        "    , Row(sequence_id=21, cal_year=2001, cal_period=8, start_date=date(2001, 7, 15), end_date=date(2001, 8, 11), days_in_period=28)\n",
        "    , Row(sequence_id=22, cal_year=2001, cal_period=9, start_date=date(2001, 8, 12), end_date=date(2001, 9, 8), days_in_period=28)\n",
        "    , Row(sequence_id=23, cal_year=2001, cal_period=10, start_date=date(2001, 9, 9), end_date=date(2001, 10, 6), days_in_period=28)\n",
        "    , Row(sequence_id=24, cal_year=2001, cal_period=11, start_date=date(2001, 10, 7), end_date=date(2001, 11, 3), days_in_period=28)\n",
        "    , Row(sequence_id=25, cal_year=2001, cal_period=12, start_date=date(2001, 11, 4), end_date=date(2001, 12, 1), days_in_period=28)\n",
        "    , Row(sequence_id=26, cal_year=2001, cal_period=13, start_date=date(2001, 12, 2), end_date=date(2001, 12, 29), days_in_period=28)\n",
        "    , Row(sequence_id=27, cal_year=2002, cal_period=1, start_date=date(2001, 12, 30), end_date=date(2002, 1, 26), days_in_period=28)\n",
        "    , Row(sequence_id=28, cal_year=2002, cal_period=2, start_date=date(2002, 1, 27), end_date=date(2002, 2, 23), days_in_period=28)\n",
        "    , Row(sequence_id=29, cal_year=2002, cal_period=3, start_date=date(2002, 2, 24), end_date=date(2002, 3, 23), days_in_period=28)\n",
        "    , Row(sequence_id=30, cal_year=2002, cal_period=4, start_date=date(2002, 3, 24), end_date=date(2002, 4, 20), days_in_period=28)\n",
        "    , Row(sequence_id=31, cal_year=2002, cal_period=5, start_date=date(2002, 4, 21), end_date=date(2002, 5, 18), days_in_period=28)\n",
        "    , Row(sequence_id=32, cal_year=2002, cal_period=6, start_date=date(2002, 5, 19), end_date=date(2002, 6, 15), days_in_period=28)\n",
        "    , Row(sequence_id=33, cal_year=2002, cal_period=7, start_date=date(2002, 6, 16), end_date=date(2002, 7, 13), days_in_period=28)\n",
        "    , Row(sequence_id=34, cal_year=2002, cal_period=8, start_date=date(2002, 7, 14), end_date=date(2002, 8, 10), days_in_period=28)\n",
        "    , Row(sequence_id=35, cal_year=2002, cal_period=9, start_date=date(2002, 8, 11), end_date=date(2002, 9, 7), days_in_period=28)\n",
        "    , Row(sequence_id=36, cal_year=2002, cal_period=10, start_date=date(2002, 9, 8), end_date=date(2002, 10, 5), days_in_period=28)\n",
        "    , Row(sequence_id=37, cal_year=2002, cal_period=11, start_date=date(2002, 10, 6), end_date=date(2002, 11, 2), days_in_period=28)\n",
        "    , Row(sequence_id=38, cal_year=2002, cal_period=12, start_date=date(2002, 11, 3), end_date=date(2002, 11, 30), days_in_period=28)\n",
        "    , Row(sequence_id=39, cal_year=2002, cal_period=13, start_date=date(2002, 12, 1), end_date=date(2002, 12, 28), days_in_period=28)\n",
        "    , Row(sequence_id=40, cal_year=2003, cal_period=1, start_date=date(2002, 12, 29), end_date=date(2003, 1, 25), days_in_period=28)\n",
        "    , Row(sequence_id=41, cal_year=2003, cal_period=2, start_date=date(2003, 1, 26), end_date=date(2003, 2, 22), days_in_period=28)\n",
        "    , Row(sequence_id=42, cal_year=2003, cal_period=3, start_date=date(2003, 2, 23), end_date=date(2003, 3, 22), days_in_period=28)\n",
        "    , Row(sequence_id=43, cal_year=2003, cal_period=4, start_date=date(2003, 3, 23), end_date=date(2003, 4, 19), days_in_period=28)\n",
        "    , Row(sequence_id=44, cal_year=2003, cal_period=5, start_date=date(2003, 4, 20), end_date=date(2003, 5, 17), days_in_period=28)\n",
        "    , Row(sequence_id=45, cal_year=2003, cal_period=6, start_date=date(2003, 5, 18), end_date=date(2003, 6, 14), days_in_period=28)\n",
        "    , Row(sequence_id=46, cal_year=2003, cal_period=7, start_date=date(2003, 6, 15), end_date=date(2003, 7, 12), days_in_period=28)\n",
        "    , Row(sequence_id=47, cal_year=2003, cal_period=8, start_date=date(2003, 7, 13), end_date=date(2003, 8, 9), days_in_period=28)\n",
        "    , Row(sequence_id=48, cal_year=2003, cal_period=9, start_date=date(2003, 8, 10), end_date=date(2003, 9, 6), days_in_period=28)\n",
        "    , Row(sequence_id=49, cal_year=2003, cal_period=10, start_date=date(2003, 9, 7), end_date=date(2003, 10, 4), days_in_period=28)\n",
        "    , Row(sequence_id=50, cal_year=2003, cal_period=11, start_date=date(2003, 10, 5), end_date=date(2003, 11, 1), days_in_period=28)\n",
        "    , Row(sequence_id=51, cal_year=2003, cal_period=12, start_date=date(2003, 11, 2), end_date=date(2003, 11, 29), days_in_period=28)\n",
        "    , Row(sequence_id=52, cal_year=2003, cal_period=13, start_date=date(2003, 11, 30), end_date=date(2004, 1, 3), days_in_period=35)\n",
        "    , Row(sequence_id=53, cal_year=2004, cal_period=1, start_date=date(2004, 1, 4), end_date=date(2004, 1, 31), days_in_period=28)\n",
        "    , Row(sequence_id=54, cal_year=2004, cal_period=2, start_date=date(2004, 2, 1), end_date=date(2004, 2, 28), days_in_period=28)\n",
        "    , Row(sequence_id=55, cal_year=2004, cal_period=3, start_date=date(2004, 2, 29), end_date=date(2004, 3, 27), days_in_period=28)\n",
        "    , Row(sequence_id=56, cal_year=2004, cal_period=4, start_date=date(2004, 3, 28), end_date=date(2004, 4, 24), days_in_period=28)\n",
        "    , Row(sequence_id=57, cal_year=2004, cal_period=5, start_date=date(2004, 4, 25), end_date=date(2004, 5, 22), days_in_period=28)\n",
        "    , Row(sequence_id=58, cal_year=2004, cal_period=6, start_date=date(2004, 5, 23), end_date=date(2004, 6, 19), days_in_period=28)\n",
        "    , Row(sequence_id=59, cal_year=2004, cal_period=7, start_date=date(2004, 6, 20), end_date=date(2004, 7, 17), days_in_period=28)\n",
        "    , Row(sequence_id=60, cal_year=2004, cal_period=8, start_date=date(2004, 7, 18), end_date=date(2004, 8, 14), days_in_period=28)\n",
        "    , Row(sequence_id=61, cal_year=2004, cal_period=9, start_date=date(2004, 8, 15), end_date=date(2004, 9, 11), days_in_period=28)\n",
        "    , Row(sequence_id=62, cal_year=2004, cal_period=10, start_date=date(2004, 9, 12), end_date=date(2004, 10, 9), days_in_period=28)\n",
        "    , Row(sequence_id=63, cal_year=2004, cal_period=11, start_date=date(2004, 10, 10), end_date=date(2004, 11, 6), days_in_period=28)\n",
        "    , Row(sequence_id=64, cal_year=2004, cal_period=12, start_date=date(2004, 11, 7), end_date=date(2004, 12, 4), days_in_period=28)\n",
        "    , Row(sequence_id=65, cal_year=2004, cal_period=13, start_date=date(2004, 12, 5), end_date=date(2005, 1, 1), days_in_period=28)\n",
        "    , Row(sequence_id=66, cal_year=2005, cal_period=1, start_date=date(2005, 1, 2), end_date=date(2005, 1, 29), days_in_period=28)\n",
        "    , Row(sequence_id=67, cal_year=2005, cal_period=2, start_date=date(2005, 1, 30), end_date=date(2005, 2, 26), days_in_period=28)\n",
        "    , Row(sequence_id=68, cal_year=2005, cal_period=3, start_date=date(2005, 2, 27), end_date=date(2005, 3, 26), days_in_period=28)\n",
        "    , Row(sequence_id=69, cal_year=2005, cal_period=4, start_date=date(2005, 3, 27), end_date=date(2005, 4, 23), days_in_period=28)\n",
        "    , Row(sequence_id=70, cal_year=2005, cal_period=5, start_date=date(2005, 4, 24), end_date=date(2005, 5, 21), days_in_period=28)\n",
        "    , Row(sequence_id=71, cal_year=2005, cal_period=6, start_date=date(2005, 5, 22), end_date=date(2005, 6, 18), days_in_period=28)\n",
        "    , Row(sequence_id=72, cal_year=2005, cal_period=7, start_date=date(2005, 6, 19), end_date=date(2005, 7, 16), days_in_period=28)\n",
        "    , Row(sequence_id=73, cal_year=2005, cal_period=8, start_date=date(2005, 7, 17), end_date=date(2005, 8, 13), days_in_period=28)\n",
        "    , Row(sequence_id=74, cal_year=2005, cal_period=9, start_date=date(2005, 8, 14), end_date=date(2005, 9, 10), days_in_period=28)\n",
        "    , Row(sequence_id=75, cal_year=2005, cal_period=10, start_date=date(2005, 9, 11), end_date=date(2005, 10, 8), days_in_period=28)\n",
        "    , Row(sequence_id=76, cal_year=2005, cal_period=11, start_date=date(2005, 10, 9), end_date=date(2005, 11, 5), days_in_period=28)\n",
        "    , Row(sequence_id=77, cal_year=2005, cal_period=12, start_date=date(2005, 11, 6), end_date=date(2005, 12, 3), days_in_period=28)\n",
        "    , Row(sequence_id=78, cal_year=2005, cal_period=13, start_date=date(2005, 12, 4), end_date=date(2005, 12, 31), days_in_period=28)\n",
        "    , Row(sequence_id=79, cal_year=2006, cal_period=1, start_date=date(2006, 1, 1), end_date=date(2006, 1, 28), days_in_period=28)\n",
        "    , Row(sequence_id=80, cal_year=2006, cal_period=2, start_date=date(2006, 1, 29), end_date=date(2006, 2, 25), days_in_period=28)\n",
        "    , Row(sequence_id=81, cal_year=2006, cal_period=3, start_date=date(2006, 2, 26), end_date=date(2006, 3, 25), days_in_period=28)\n",
        "    , Row(sequence_id=82, cal_year=2006, cal_period=4, start_date=date(2006, 3, 26), end_date=date(2006, 4, 22), days_in_period=28)\n",
        "    , Row(sequence_id=83, cal_year=2006, cal_period=5, start_date=date(2006, 4, 23), end_date=date(2006, 5, 20), days_in_period=28)\n",
        "    , Row(sequence_id=84, cal_year=2006, cal_period=6, start_date=date(2006, 5, 21), end_date=date(2006, 6, 17), days_in_period=28)\n",
        "    , Row(sequence_id=85, cal_year=2006, cal_period=7, start_date=date(2006, 6, 18), end_date=date(2006, 7, 15), days_in_period=28)\n",
        "    , Row(sequence_id=86, cal_year=2006, cal_period=8, start_date=date(2006, 7, 16), end_date=date(2006, 8, 12), days_in_period=28)\n",
        "    , Row(sequence_id=87, cal_year=2006, cal_period=9, start_date=date(2006, 8, 13), end_date=date(2006, 9, 9), days_in_period=28)\n",
        "    , Row(sequence_id=88, cal_year=2006, cal_period=10, start_date=date(2006, 9, 10), end_date=date(2006, 10, 7), days_in_period=28)\n",
        "    , Row(sequence_id=89, cal_year=2006, cal_period=11, start_date=date(2006, 10, 8), end_date=date(2006, 11, 4), days_in_period=28)\n",
        "    , Row(sequence_id=90, cal_year=2006, cal_period=12, start_date=date(2006, 11, 5), end_date=date(2006, 12, 2), days_in_period=28)\n",
        "    , Row(sequence_id=91, cal_year=2006, cal_period=13, start_date=date(2006, 12, 3), end_date=date(2006, 12, 30), days_in_period=28)\n",
        "    , Row(sequence_id=92, cal_year=2007, cal_period=1, start_date=date(2006, 12, 31), end_date=date(2007, 1, 27), days_in_period=28)\n",
        "    , Row(sequence_id=93, cal_year=2007, cal_period=2, start_date=date(2007, 1, 28), end_date=date(2007, 2, 24), days_in_period=28)\n",
        "    , Row(sequence_id=94, cal_year=2007, cal_period=3, start_date=date(2007, 2, 25), end_date=date(2007, 3, 24), days_in_period=28)\n",
        "    , Row(sequence_id=95, cal_year=2007, cal_period=4, start_date=date(2007, 3, 25), end_date=date(2007, 4, 21), days_in_period=28)\n",
        "    , Row(sequence_id=96, cal_year=2007, cal_period=5, start_date=date(2007, 4, 22), end_date=date(2007, 5, 19), days_in_period=28)\n",
        "    , Row(sequence_id=97, cal_year=2007, cal_period=6, start_date=date(2007, 5, 20), end_date=date(2007, 6, 16), days_in_period=28)\n",
        "    , Row(sequence_id=98, cal_year=2007, cal_period=7, start_date=date(2007, 6, 17), end_date=date(2007, 7, 14), days_in_period=28)\n",
        "    , Row(sequence_id=99, cal_year=2007, cal_period=8, start_date=date(2007, 7, 15), end_date=date(2007, 8, 11), days_in_period=28)\n",
        "    , Row(sequence_id=100, cal_year=2007, cal_period=9, start_date=date(2007, 8, 12), end_date=date(2007, 9, 8), days_in_period=28)\n",
        "    , Row(sequence_id=101, cal_year=2007, cal_period=10, start_date=date(2007, 9, 9), end_date=date(2007, 10, 6), days_in_period=28)\n",
        "    , Row(sequence_id=102, cal_year=2007, cal_period=11, start_date=date(2007, 10, 7), end_date=date(2007, 11, 3), days_in_period=28)\n",
        "    , Row(sequence_id=103, cal_year=2007, cal_period=12, start_date=date(2007, 11, 4), end_date=date(2007, 12, 1), days_in_period=28)\n",
        "    , Row(sequence_id=104, cal_year=2007, cal_period=13, start_date=date(2007, 12, 2), end_date=date(2007, 12, 29), days_in_period=28)\n",
        "    , Row(sequence_id=105, cal_year=2008, cal_period=1, start_date=date(2007, 12, 30), end_date=date(2008, 1, 26), days_in_period=28)\n",
        "    , Row(sequence_id=106, cal_year=2008, cal_period=2, start_date=date(2008, 1, 27), end_date=date(2008, 2, 23), days_in_period=28)\n",
        "    , Row(sequence_id=107, cal_year=2008, cal_period=3, start_date=date(2008, 2, 24), end_date=date(2008, 3, 22), days_in_period=28)\n",
        "    , Row(sequence_id=108, cal_year=2008, cal_period=4, start_date=date(2008, 3, 23), end_date=date(2008, 4, 19), days_in_period=28)\n",
        "    , Row(sequence_id=109, cal_year=2008, cal_period=5, start_date=date(2008, 4, 20), end_date=date(2008, 5, 17), days_in_period=28)\n",
        "    , Row(sequence_id=110, cal_year=2008, cal_period=6, start_date=date(2008, 5, 18), end_date=date(2008, 6, 14), days_in_period=28)\n",
        "    , Row(sequence_id=111, cal_year=2008, cal_period=7, start_date=date(2008, 6, 15), end_date=date(2008, 7, 12), days_in_period=28)\n",
        "    , Row(sequence_id=112, cal_year=2008, cal_period=8, start_date=date(2008, 7, 13), end_date=date(2008, 8, 9), days_in_period=28)\n",
        "    , Row(sequence_id=113, cal_year=2008, cal_period=9, start_date=date(2008, 8, 10), end_date=date(2008, 9, 6), days_in_period=28)\n",
        "    , Row(sequence_id=114, cal_year=2008, cal_period=10, start_date=date(2008, 9, 7), end_date=date(2008, 10, 4), days_in_period=28)\n",
        "    , Row(sequence_id=115, cal_year=2008, cal_period=11, start_date=date(2008, 10, 5), end_date=date(2008, 11, 1), days_in_period=28)\n",
        "    , Row(sequence_id=116, cal_year=2008, cal_period=12, start_date=date(2008, 11, 2), end_date=date(2008, 11, 29), days_in_period=28)\n",
        "    , Row(sequence_id=117, cal_year=2008, cal_period=13, start_date=date(2008, 11, 30), end_date=date(2009, 1, 3), days_in_period=35)\n",
        "    , Row(sequence_id=118, cal_year=2009, cal_period=1, start_date=date(2009, 1, 4), end_date=date(2009, 1, 31), days_in_period=28)\n",
        "    , Row(sequence_id=119, cal_year=2009, cal_period=2, start_date=date(2009, 2, 1), end_date=date(2009, 2, 28), days_in_period=28)\n",
        "    , Row(sequence_id=120, cal_year=2009, cal_period=3, start_date=date(2009, 3, 1), end_date=date(2009, 3, 28), days_in_period=28)\n",
        "    , Row(sequence_id=121, cal_year=2009, cal_period=4, start_date=date(2009, 3, 29), end_date=date(2009, 4, 25), days_in_period=28)\n",
        "    , Row(sequence_id=122, cal_year=2009, cal_period=5, start_date=date(2009, 4, 26), end_date=date(2009, 5, 23), days_in_period=28)\n",
        "    , Row(sequence_id=123, cal_year=2009, cal_period=6, start_date=date(2009, 5, 24), end_date=date(2009, 6, 20), days_in_period=28)\n",
        "    , Row(sequence_id=124, cal_year=2009, cal_period=7, start_date=date(2009, 6, 21), end_date=date(2009, 7, 18), days_in_period=28)\n",
        "    , Row(sequence_id=125, cal_year=2009, cal_period=8, start_date=date(2009, 7, 19), end_date=date(2009, 8, 15), days_in_period=28)\n",
        "    , Row(sequence_id=126, cal_year=2009, cal_period=9, start_date=date(2009, 8, 16), end_date=date(2009, 9, 12), days_in_period=28)\n",
        "    , Row(sequence_id=127, cal_year=2009, cal_period=10, start_date=date(2009, 9, 13), end_date=date(2009, 10, 10), days_in_period=28)\n",
        "    , Row(sequence_id=128, cal_year=2009, cal_period=11, start_date=date(2009, 10, 11), end_date=date(2009, 11, 7), days_in_period=28)\n",
        "    , Row(sequence_id=129, cal_year=2009, cal_period=12, start_date=date(2009, 11, 8), end_date=date(2009, 12, 5), days_in_period=28)\n",
        "    , Row(sequence_id=130, cal_year=2009, cal_period=13, start_date=date(2009, 12, 6), end_date=date(2010, 1, 2), days_in_period=28)\n",
        "    , Row(sequence_id=131, cal_year=2010, cal_period=1, start_date=date(2010, 1, 3), end_date=date(2010, 1, 30), days_in_period=28)\n",
        "    , Row(sequence_id=132, cal_year=2010, cal_period=2, start_date=date(2010, 1, 31), end_date=date(2010, 2, 27), days_in_period=28)\n",
        "    , Row(sequence_id=133, cal_year=2010, cal_period=3, start_date=date(2010, 2, 28), end_date=date(2010, 3, 27), days_in_period=28)\n",
        "    , Row(sequence_id=134, cal_year=2010, cal_period=4, start_date=date(2010, 3, 28), end_date=date(2010, 4, 24), days_in_period=28)\n",
        "    , Row(sequence_id=135, cal_year=2010, cal_period=5, start_date=date(2010, 4, 25), end_date=date(2010, 5, 22), days_in_period=28)\n",
        "    , Row(sequence_id=136, cal_year=2010, cal_period=6, start_date=date(2010, 5, 23), end_date=date(2010, 6, 19), days_in_period=28)\n",
        "    , Row(sequence_id=137, cal_year=2010, cal_period=7, start_date=date(2010, 6, 20), end_date=date(2010, 7, 17), days_in_period=28)\n",
        "    , Row(sequence_id=138, cal_year=2010, cal_period=8, start_date=date(2010, 7, 18), end_date=date(2010, 8, 14), days_in_period=28)\n",
        "    , Row(sequence_id=139, cal_year=2010, cal_period=9, start_date=date(2010, 8, 15), end_date=date(2010, 9, 11), days_in_period=28)\n",
        "    , Row(sequence_id=140, cal_year=2010, cal_period=10, start_date=date(2010, 9, 12), end_date=date(2010, 10, 9), days_in_period=28)\n",
        "    , Row(sequence_id=141, cal_year=2010, cal_period=11, start_date=date(2010, 10, 10), end_date=date(2010, 11, 6), days_in_period=28)\n",
        "    , Row(sequence_id=142, cal_year=2010, cal_period=12, start_date=date(2010, 11, 7), end_date=date(2010, 12, 4), days_in_period=28)\n",
        "    , Row(sequence_id=143, cal_year=2010, cal_period=13, start_date=date(2010, 12, 5), end_date=date(2011, 1, 1), days_in_period=28)\n",
        "    , Row(sequence_id=144, cal_year=2011, cal_period=1, start_date=date(2011, 1, 2), end_date=date(2011, 1, 29), days_in_period=28)\n",
        "    , Row(sequence_id=145, cal_year=2011, cal_period=2, start_date=date(2011, 1, 30), end_date=date(2011, 2, 26), days_in_period=28)\n",
        "    , Row(sequence_id=146, cal_year=2011, cal_period=3, start_date=date(2011, 2, 27), end_date=date(2011, 3, 26), days_in_period=28)\n",
        "    , Row(sequence_id=147, cal_year=2011, cal_period=4, start_date=date(2011, 3, 27), end_date=date(2011, 4, 23), days_in_period=28)\n",
        "    , Row(sequence_id=148, cal_year=2011, cal_period=5, start_date=date(2011, 4, 24), end_date=date(2011, 5, 21), days_in_period=28)\n",
        "    , Row(sequence_id=149, cal_year=2011, cal_period=6, start_date=date(2011, 5, 22), end_date=date(2011, 6, 18), days_in_period=28)\n",
        "    , Row(sequence_id=150, cal_year=2011, cal_period=7, start_date=date(2011, 6, 19), end_date=date(2011, 7, 16), days_in_period=28)\n",
        "    , Row(sequence_id=151, cal_year=2011, cal_period=8, start_date=date(2011, 7, 17), end_date=date(2011, 8, 13), days_in_period=28)\n",
        "    , Row(sequence_id=152, cal_year=2011, cal_period=9, start_date=date(2011, 8, 14), end_date=date(2011, 9, 10), days_in_period=28)\n",
        "    , Row(sequence_id=153, cal_year=2011, cal_period=10, start_date=date(2011, 9, 11), end_date=date(2011, 10, 8), days_in_period=28)\n",
        "    , Row(sequence_id=154, cal_year=2011, cal_period=11, start_date=date(2011, 10, 9), end_date=date(2011, 11, 5), days_in_period=28)\n",
        "    , Row(sequence_id=155, cal_year=2011, cal_period=12, start_date=date(2011, 11, 6), end_date=date(2011, 12, 3), days_in_period=28)\n",
        "    , Row(sequence_id=156, cal_year=2011, cal_period=13, start_date=date(2011, 12, 4), end_date=date(2011, 12, 31), days_in_period=28)\n",
        "    , Row(sequence_id=157, cal_year=2012, cal_period=1, start_date=date(2012, 1, 1), end_date=date(2012, 1, 28), days_in_period=28)\n",
        "    , Row(sequence_id=158, cal_year=2012, cal_period=2, start_date=date(2012, 1, 29), end_date=date(2012, 2, 25), days_in_period=28)\n",
        "    , Row(sequence_id=159, cal_year=2012, cal_period=3, start_date=date(2012, 2, 26), end_date=date(2012, 3, 24), days_in_period=28)\n",
        "    , Row(sequence_id=160, cal_year=2012, cal_period=4, start_date=date(2012, 3, 25), end_date=date(2012, 4, 21), days_in_period=28)\n",
        "    , Row(sequence_id=161, cal_year=2012, cal_period=5, start_date=date(2012, 4, 22), end_date=date(2012, 5, 19), days_in_period=28)\n",
        "    , Row(sequence_id=162, cal_year=2012, cal_period=6, start_date=date(2012, 5, 20), end_date=date(2012, 6, 16), days_in_period=28)\n",
        "    , Row(sequence_id=163, cal_year=2012, cal_period=7, start_date=date(2012, 6, 17), end_date=date(2012, 7, 14), days_in_period=28)\n",
        "    , Row(sequence_id=164, cal_year=2012, cal_period=8, start_date=date(2012, 7, 15), end_date=date(2012, 8, 11), days_in_period=28)\n",
        "    , Row(sequence_id=165, cal_year=2012, cal_period=9, start_date=date(2012, 8, 12), end_date=date(2012, 9, 8), days_in_period=28)\n",
        "    , Row(sequence_id=166, cal_year=2012, cal_period=10, start_date=date(2012, 9, 9), end_date=date(2012, 10, 6), days_in_period=28)\n",
        "    , Row(sequence_id=167, cal_year=2012, cal_period=11, start_date=date(2012, 10, 7), end_date=date(2012, 11, 3), days_in_period=28)\n",
        "    , Row(sequence_id=168, cal_year=2012, cal_period=12, start_date=date(2012, 11, 4), end_date=date(2012, 12, 1), days_in_period=28)\n",
        "    , Row(sequence_id=169, cal_year=2012, cal_period=13, start_date=date(2012, 12, 2), end_date=date(2012, 12, 29), days_in_period=28)\n",
        "    , Row(sequence_id=170, cal_year=2013, cal_period=1, start_date=date(2012, 12, 30), end_date=date(2013, 1, 26), days_in_period=28)\n",
        "    , Row(sequence_id=171, cal_year=2013, cal_period=2, start_date=date(2013, 1, 27), end_date=date(2013, 2, 23), days_in_period=28)\n",
        "    , Row(sequence_id=172, cal_year=2013, cal_period=3, start_date=date(2013, 2, 24), end_date=date(2013, 3, 23), days_in_period=28)\n",
        "    , Row(sequence_id=173, cal_year=2013, cal_period=4, start_date=date(2013, 3, 24), end_date=date(2013, 4, 20), days_in_period=28)\n",
        "    , Row(sequence_id=174, cal_year=2013, cal_period=5, start_date=date(2013, 4, 21), end_date=date(2013, 5, 18), days_in_period=28)\n",
        "    , Row(sequence_id=175, cal_year=2013, cal_period=6, start_date=date(2013, 5, 19), end_date=date(2013, 6, 15), days_in_period=28)\n",
        "    , Row(sequence_id=176, cal_year=2013, cal_period=7, start_date=date(2013, 6, 16), end_date=date(2013, 7, 13), days_in_period=28)\n",
        "    , Row(sequence_id=177, cal_year=2013, cal_period=8, start_date=date(2013, 7, 14), end_date=date(2013, 8, 10), days_in_period=28)\n",
        "    , Row(sequence_id=178, cal_year=2013, cal_period=9, start_date=date(2013, 8, 11), end_date=date(2013, 9, 7), days_in_period=28)\n",
        "    , Row(sequence_id=179, cal_year=2013, cal_period=10, start_date=date(2013, 9, 8), end_date=date(2013, 10, 5), days_in_period=28)\n",
        "    , Row(sequence_id=180, cal_year=2013, cal_period=11, start_date=date(2013, 10, 6), end_date=date(2013, 11, 2), days_in_period=28)\n",
        "    , Row(sequence_id=181, cal_year=2013, cal_period=12, start_date=date(2013, 11, 3), end_date=date(2013, 11, 30), days_in_period=28)\n",
        "    , Row(sequence_id=182, cal_year=2013, cal_period=13, start_date=date(2013, 12, 1), end_date=date(2013, 12, 28), days_in_period=28)\n",
        "    , Row(sequence_id=183, cal_year=2014, cal_period=1, start_date=date(2013, 12, 29), end_date=date(2014, 1, 25), days_in_period=28)\n",
        "    , Row(sequence_id=184, cal_year=2014, cal_period=2, start_date=date(2014, 1, 26), end_date=date(2014, 2, 22), days_in_period=28)\n",
        "    , Row(sequence_id=185, cal_year=2014, cal_period=3, start_date=date(2014, 2, 23), end_date=date(2014, 3, 22), days_in_period=28)\n",
        "    , Row(sequence_id=186, cal_year=2014, cal_period=4, start_date=date(2014, 3, 23), end_date=date(2014, 4, 19), days_in_period=28)\n",
        "    , Row(sequence_id=187, cal_year=2014, cal_period=5, start_date=date(2014, 4, 20), end_date=date(2014, 5, 17), days_in_period=28)\n",
        "    , Row(sequence_id=188, cal_year=2014, cal_period=6, start_date=date(2014, 5, 18), end_date=date(2014, 6, 14), days_in_period=28)\n",
        "    , Row(sequence_id=189, cal_year=2014, cal_period=7, start_date=date(2014, 6, 15), end_date=date(2014, 7, 12), days_in_period=28)\n",
        "    , Row(sequence_id=190, cal_year=2014, cal_period=8, start_date=date(2014, 7, 13), end_date=date(2014, 8, 9), days_in_period=28)\n",
        "    , Row(sequence_id=191, cal_year=2014, cal_period=9, start_date=date(2014, 8, 10), end_date=date(2014, 9, 6), days_in_period=28)\n",
        "    , Row(sequence_id=192, cal_year=2014, cal_period=10, start_date=date(2014, 9, 7), end_date=date(2014, 10, 4), days_in_period=28)\n",
        "    , Row(sequence_id=193, cal_year=2014, cal_period=11, start_date=date(2014, 10, 5), end_date=date(2014, 11, 1), days_in_period=28)\n",
        "    , Row(sequence_id=194, cal_year=2014, cal_period=12, start_date=date(2014, 11, 2), end_date=date(2014, 11, 29), days_in_period=28)\n",
        "    , Row(sequence_id=195, cal_year=2014, cal_period=13, start_date=date(2014, 11, 30), end_date=date(2015, 1, 3), days_in_period=35)\n",
        "    , Row(sequence_id=196, cal_year=2015, cal_period=1, start_date=date(2015, 1, 4), end_date=date(2015, 1, 31), days_in_period=28)\n",
        "    , Row(sequence_id=197, cal_year=2015, cal_period=2, start_date=date(2015, 2, 1), end_date=date(2015, 2, 28), days_in_period=28)\n",
        "    , Row(sequence_id=198, cal_year=2015, cal_period=3, start_date=date(2015, 3, 1), end_date=date(2015, 3, 28), days_in_period=28)\n",
        "    , Row(sequence_id=199, cal_year=2015, cal_period=4, start_date=date(2015, 3, 29), end_date=date(2015, 4, 25), days_in_period=28)\n",
        "    , Row(sequence_id=200, cal_year=2015, cal_period=5, start_date=date(2015, 4, 26), end_date=date(2015, 5, 23), days_in_period=28)\n",
        "    , Row(sequence_id=201, cal_year=2015, cal_period=6, start_date=date(2015, 5, 24), end_date=date(2015, 6, 20), days_in_period=28)\n",
        "    , Row(sequence_id=202, cal_year=2015, cal_period=7, start_date=date(2015, 6, 21), end_date=date(2015, 7, 18), days_in_period=28)\n",
        "    , Row(sequence_id=203, cal_year=2015, cal_period=8, start_date=date(2015, 7, 19), end_date=date(2015, 8, 15), days_in_period=28)\n",
        "    , Row(sequence_id=204, cal_year=2015, cal_period=9, start_date=date(2015, 8, 16), end_date=date(2015, 9, 12), days_in_period=28)\n",
        "    , Row(sequence_id=205, cal_year=2015, cal_period=10, start_date=date(2015, 9, 13), end_date=date(2015, 10, 10), days_in_period=28)\n",
        "    , Row(sequence_id=206, cal_year=2015, cal_period=11, start_date=date(2015, 10, 11), end_date=date(2015, 11, 7), days_in_period=28)\n",
        "    , Row(sequence_id=207, cal_year=2015, cal_period=12, start_date=date(2015, 11, 8), end_date=date(2015, 12, 5), days_in_period=28)\n",
        "    , Row(sequence_id=208, cal_year=2015, cal_period=13, start_date=date(2015, 12, 6), end_date=date(2016, 1, 2), days_in_period=28)\n",
        "    , Row(sequence_id=209, cal_year=2016, cal_period=1, start_date=date(2016, 1, 3), end_date=date(2016, 1, 30), days_in_period=28)\n",
        "    , Row(sequence_id=210, cal_year=2016, cal_period=2, start_date=date(2016, 1, 31), end_date=date(2016, 2, 27), days_in_period=28)\n",
        "    , Row(sequence_id=211, cal_year=2016, cal_period=3, start_date=date(2016, 2, 28), end_date=date(2016, 3, 26), days_in_period=28)\n",
        "    , Row(sequence_id=212, cal_year=2016, cal_period=4, start_date=date(2016, 3, 27), end_date=date(2016, 4, 23), days_in_period=28)\n",
        "    , Row(sequence_id=213, cal_year=2016, cal_period=5, start_date=date(2016, 4, 24), end_date=date(2016, 5, 21), days_in_period=28)\n",
        "    , Row(sequence_id=214, cal_year=2016, cal_period=6, start_date=date(2016, 5, 22), end_date=date(2016, 6, 18), days_in_period=28)\n",
        "    , Row(sequence_id=215, cal_year=2016, cal_period=7, start_date=date(2016, 6, 19), end_date=date(2016, 7, 16), days_in_period=28)\n",
        "    , Row(sequence_id=216, cal_year=2016, cal_period=8, start_date=date(2016, 7, 17), end_date=date(2016, 8, 13), days_in_period=28)\n",
        "    , Row(sequence_id=217, cal_year=2016, cal_period=9, start_date=date(2016, 8, 14), end_date=date(2016, 9, 10), days_in_period=28)\n",
        "    , Row(sequence_id=218, cal_year=2016, cal_period=10, start_date=date(2016, 9, 11), end_date=date(2016, 10, 8), days_in_period=28)\n",
        "    , Row(sequence_id=219, cal_year=2016, cal_period=11, start_date=date(2016, 10, 9), end_date=date(2016, 11, 5), days_in_period=28)\n",
        "    , Row(sequence_id=220, cal_year=2016, cal_period=12, start_date=date(2016, 11, 6), end_date=date(2016, 12, 3), days_in_period=28)\n",
        "    , Row(sequence_id=221, cal_year=2016, cal_period=13, start_date=date(2016, 12, 4), end_date=date(2016, 12, 31), days_in_period=28)\n",
        "    , Row(sequence_id=222, cal_year=2017, cal_period=1, start_date=date(2017, 1, 1), end_date=date(2017, 1, 28), days_in_period=28)\n",
        "    , Row(sequence_id=223, cal_year=2017, cal_period=2, start_date=date(2017, 1, 29), end_date=date(2017, 2, 25), days_in_period=28)\n",
        "    , Row(sequence_id=224, cal_year=2017, cal_period=3, start_date=date(2017, 2, 26), end_date=date(2017, 3, 25), days_in_period=28)\n",
        "    , Row(sequence_id=225, cal_year=2017, cal_period=4, start_date=date(2017, 3, 26), end_date=date(2017, 4, 22), days_in_period=28)\n",
        "    , Row(sequence_id=226, cal_year=2017, cal_period=5, start_date=date(2017, 4, 23), end_date=date(2017, 5, 20), days_in_period=28)\n",
        "    , Row(sequence_id=227, cal_year=2017, cal_period=6, start_date=date(2017, 5, 21), end_date=date(2017, 6, 17), days_in_period=28)\n",
        "    , Row(sequence_id=228, cal_year=2017, cal_period=7, start_date=date(2017, 6, 18), end_date=date(2017, 7, 15), days_in_period=28)\n",
        "    , Row(sequence_id=229, cal_year=2017, cal_period=8, start_date=date(2017, 7, 16), end_date=date(2017, 8, 12), days_in_period=28)\n",
        "    , Row(sequence_id=230, cal_year=2017, cal_period=9, start_date=date(2017, 8, 13), end_date=date(2017, 9, 9), days_in_period=28)\n",
        "    , Row(sequence_id=231, cal_year=2017, cal_period=10, start_date=date(2017, 9, 10), end_date=date(2017, 10, 7), days_in_period=28)\n",
        "    , Row(sequence_id=232, cal_year=2017, cal_period=11, start_date=date(2017, 10, 8), end_date=date(2017, 11, 4), days_in_period=28)\n",
        "    , Row(sequence_id=233, cal_year=2017, cal_period=12, start_date=date(2017, 11, 5), end_date=date(2017, 12, 2), days_in_period=28)\n",
        "    , Row(sequence_id=234, cal_year=2017, cal_period=13, start_date=date(2017, 12, 3), end_date=date(2017, 12, 30), days_in_period=28)\n",
        "    , Row(sequence_id=235, cal_year=2018, cal_period=1, start_date=date(2017, 12, 31), end_date=date(2018, 1, 27), days_in_period=28)\n",
        "    , Row(sequence_id=236, cal_year=2018, cal_period=2, start_date=date(2018, 1, 28), end_date=date(2018, 2, 24), days_in_period=28)\n",
        "    , Row(sequence_id=237, cal_year=2018, cal_period=3, start_date=date(2018, 2, 25), end_date=date(2018, 3, 24), days_in_period=28)\n",
        "    , Row(sequence_id=238, cal_year=2018, cal_period=4, start_date=date(2018, 3, 25), end_date=date(2018, 4, 21), days_in_period=28)\n",
        "    , Row(sequence_id=239, cal_year=2018, cal_period=5, start_date=date(2018, 4, 22), end_date=date(2018, 5, 19), days_in_period=28)\n",
        "    , Row(sequence_id=240, cal_year=2018, cal_period=6, start_date=date(2018, 5, 20), end_date=date(2018, 6, 16), days_in_period=28)\n",
        "    , Row(sequence_id=241, cal_year=2018, cal_period=7, start_date=date(2018, 6, 17), end_date=date(2018, 7, 14), days_in_period=28)\n",
        "    , Row(sequence_id=242, cal_year=2018, cal_period=8, start_date=date(2018, 7, 15), end_date=date(2018, 8, 11), days_in_period=28)\n",
        "    , Row(sequence_id=243, cal_year=2018, cal_period=9, start_date=date(2018, 8, 12), end_date=date(2018, 9, 8), days_in_period=28)\n",
        "    , Row(sequence_id=244, cal_year=2018, cal_period=10, start_date=date(2018, 9, 9), end_date=date(2018, 10, 6), days_in_period=28)\n",
        "    , Row(sequence_id=245, cal_year=2018, cal_period=11, start_date=date(2018, 10, 7), end_date=date(2018, 11, 3), days_in_period=28)\n",
        "    , Row(sequence_id=246, cal_year=2018, cal_period=12, start_date=date(2018, 11, 4), end_date=date(2018, 12, 1), days_in_period=28)\n",
        "    , Row(sequence_id=247, cal_year=2018, cal_period=13, start_date=date(2018, 12, 2), end_date=date(2018, 12, 29), days_in_period=28)\n",
        "    , Row(sequence_id=248, cal_year=2019, cal_period=1, start_date=date(2018, 12, 30), end_date=date(2019, 1, 26), days_in_period=28)\n",
        "    , Row(sequence_id=249, cal_year=2019, cal_period=2, start_date=date(2019, 1, 27), end_date=date(2019, 2, 23), days_in_period=28)\n",
        "    , Row(sequence_id=250, cal_year=2019, cal_period=3, start_date=date(2019, 2, 24), end_date=date(2019, 3, 23), days_in_period=28)\n",
        "    , Row(sequence_id=251, cal_year=2019, cal_period=4, start_date=date(2019, 3, 24), end_date=date(2019, 4, 20), days_in_period=28)\n",
        "    , Row(sequence_id=252, cal_year=2019, cal_period=5, start_date=date(2019, 4, 21), end_date=date(2019, 5, 18), days_in_period=28)\n",
        "    , Row(sequence_id=253, cal_year=2019, cal_period=6, start_date=date(2019, 5, 19), end_date=date(2019, 6, 15), days_in_period=28)\n",
        "    , Row(sequence_id=254, cal_year=2019, cal_period=7, start_date=date(2019, 6, 16), end_date=date(2019, 7, 13), days_in_period=28)\n",
        "    , Row(sequence_id=255, cal_year=2019, cal_period=8, start_date=date(2019, 7, 14), end_date=date(2019, 8, 10), days_in_period=28)\n",
        "    , Row(sequence_id=256, cal_year=2019, cal_period=9, start_date=date(2019, 8, 11), end_date=date(2019, 9, 7), days_in_period=28)\n",
        "    , Row(sequence_id=257, cal_year=2019, cal_period=10, start_date=date(2019, 9, 8), end_date=date(2019, 10, 5), days_in_period=28)\n",
        "    , Row(sequence_id=258, cal_year=2019, cal_period=11, start_date=date(2019, 10, 6), end_date=date(2019, 11, 2), days_in_period=28)\n",
        "    , Row(sequence_id=259, cal_year=2019, cal_period=12, start_date=date(2019, 11, 3), end_date=date(2019, 11, 30), days_in_period=28)\n",
        "    , Row(sequence_id=260, cal_year=2019, cal_period=13, start_date=date(2019, 12, 1), end_date=date(2019, 12, 28), days_in_period=28)\n",
        "    , Row(sequence_id=261, cal_year=2020, cal_period=1, start_date=date(2019, 12, 29), end_date=date(2020, 1, 25), days_in_period=28)\n",
        "    , Row(sequence_id=262, cal_year=2020, cal_period=2, start_date=date(2020, 1, 26), end_date=date(2020, 2, 22), days_in_period=28)\n",
        "    , Row(sequence_id=263, cal_year=2020, cal_period=3, start_date=date(2020, 2, 23), end_date=date(2020, 3, 21), days_in_period=28)\n",
        "    , Row(sequence_id=264, cal_year=2020, cal_period=4, start_date=date(2020, 3, 22), end_date=date(2020, 4, 18), days_in_period=28)\n",
        "    , Row(sequence_id=265, cal_year=2020, cal_period=5, start_date=date(2020, 4, 19), end_date=date(2020, 5, 16), days_in_period=28)\n",
        "    , Row(sequence_id=266, cal_year=2020, cal_period=6, start_date=date(2020, 5, 17), end_date=date(2020, 6, 13), days_in_period=28)\n",
        "    , Row(sequence_id=267, cal_year=2020, cal_period=7, start_date=date(2020, 6, 14), end_date=date(2020, 7, 11), days_in_period=28)\n",
        "    , Row(sequence_id=268, cal_year=2020, cal_period=8, start_date=date(2020, 7, 12), end_date=date(2020, 8, 8), days_in_period=28)\n",
        "    , Row(sequence_id=269, cal_year=2020, cal_period=9, start_date=date(2020, 8, 9), end_date=date(2020, 9, 5), days_in_period=28)\n",
        "    , Row(sequence_id=270, cal_year=2020, cal_period=10, start_date=date(2020, 9, 6), end_date=date(2020, 10, 3), days_in_period=28)\n",
        "    , Row(sequence_id=271, cal_year=2020, cal_period=11, start_date=date(2020, 10, 4), end_date=date(2020, 10, 31), days_in_period=28)\n",
        "    , Row(sequence_id=272, cal_year=2020, cal_period=12, start_date=date(2020, 11, 1), end_date=date(2020, 11, 28), days_in_period=28)\n",
        "    , Row(sequence_id=273, cal_year=2020, cal_period=13, start_date=date(2020, 11, 29), end_date=date(2021, 1, 2), days_in_period=35)\n",
        "    , Row(sequence_id=274, cal_year=2021, cal_period=1, start_date=date(2021, 1, 3), end_date=date(2021, 1, 30), days_in_period=28)\n",
        "    , Row(sequence_id=275, cal_year=2021, cal_period=2, start_date=date(2021, 1, 31), end_date=date(2021, 2, 27), days_in_period=28)\n",
        "    , Row(sequence_id=276, cal_year=2021, cal_period=3, start_date=date(2021, 2, 28), end_date=date(2021, 3, 27), days_in_period=28)\n",
        "    , Row(sequence_id=277, cal_year=2021, cal_period=4, start_date=date(2021, 3, 28), end_date=date(2021, 4, 24), days_in_period=28)\n",
        "    , Row(sequence_id=278, cal_year=2021, cal_period=5, start_date=date(2021, 4, 25), end_date=date(2021, 5, 22), days_in_period=28)\n",
        "    , Row(sequence_id=279, cal_year=2021, cal_period=6, start_date=date(2021, 5, 23), end_date=date(2021, 6, 19), days_in_period=28)\n",
        "    , Row(sequence_id=280, cal_year=2021, cal_period=7, start_date=date(2021, 6, 20), end_date=date(2021, 7, 17), days_in_period=28)\n",
        "    , Row(sequence_id=281, cal_year=2021, cal_period=8, start_date=date(2021, 7, 18), end_date=date(2021, 8, 14), days_in_period=28)\n",
        "    , Row(sequence_id=282, cal_year=2021, cal_period=9, start_date=date(2021, 8, 15), end_date=date(2021, 9, 11), days_in_period=28)\n",
        "    , Row(sequence_id=283, cal_year=2021, cal_period=10, start_date=date(2021, 9, 12), end_date=date(2021, 10, 9), days_in_period=28)\n",
        "    , Row(sequence_id=284, cal_year=2021, cal_period=11, start_date=date(2021, 10, 10), end_date=date(2021, 11, 6), days_in_period=28)\n",
        "    , Row(sequence_id=285, cal_year=2021, cal_period=12, start_date=date(2021, 11, 7), end_date=date(2021, 12, 4), days_in_period=28)\n",
        "    , Row(sequence_id=286, cal_year=2021, cal_period=13, start_date=date(2021, 12, 5), end_date=date(2022, 1, 1), days_in_period=28)\n",
        "\n",
        "]\n",
        "\n",
        "ad_promo_mc_data = [\n",
        "    # 2015\n",
        "      Row(sequence_id=1, cal_year=2015, cal_month=1,  start_date=date(2015,  1,  1), end_date=date(2015,  1, 28), weeks_in_month=4)\n",
        "    , Row(sequence_id=1, cal_year=2015, cal_month=2,  start_date=date(2015,  1, 29), end_date=date(2015,  2, 25), weeks_in_month=4)\n",
        "    , Row(sequence_id=1, cal_year=2015, cal_month=3,  start_date=date(2015,  2, 26), end_date=date(2015,  4,  1), weeks_in_month=5)\n",
        "    , Row(sequence_id=1, cal_year=2015, cal_month=4,  start_date=date(2015,  4,  2), end_date=date(2015,  4, 29), weeks_in_month=4)\n",
        "    , Row(sequence_id=1, cal_year=2015, cal_month=5,  start_date=date(2015,  4, 30), end_date=date(2015,  5, 27), weeks_in_month=4)\n",
        "    , Row(sequence_id=1, cal_year=2015, cal_month=6,  start_date=date(2015,  5, 28), end_date=date(2015,  7,  1), weeks_in_month=5)\n",
        "    , Row(sequence_id=1, cal_year=2015, cal_month=7,  start_date=date(2015,  7,  2), end_date=date(2015,  7, 29), weeks_in_month=4)\n",
        "    , Row(sequence_id=1, cal_year=2015, cal_month=8,  start_date=date(2015,  7, 30), end_date=date(2015,  8, 26), weeks_in_month=4)\n",
        "    , Row(sequence_id=1, cal_year=2015, cal_month=9,  start_date=date(2015,  8, 27), end_date=date(2015,  9, 30), weeks_in_month=5)\n",
        "    , Row(sequence_id=1, cal_year=2015, cal_month=10, start_date=date(2015, 10,  1), end_date=date(2015, 10, 28), weeks_in_month=4)\n",
        "    , Row(sequence_id=1, cal_year=2015, cal_month=11, start_date=date(2015, 10, 29), end_date=date(2015, 12,  2), weeks_in_month=5)\n",
        "    , Row(sequence_id=1, cal_year=2015, cal_month=12, start_date=date(2015, 12,  3), end_date=date(2015, 12, 30), weeks_in_month=4)\n",
        "    # 2016\n",
        "    , Row(sequence_id=1, cal_year=2016, cal_month=1,  start_date=date(2015, 12, 31), end_date=date(2016,  1, 27), weeks_in_month=4)\n",
        "    , Row(sequence_id=1, cal_year=2016, cal_month=2,  start_date=date(2016,  1, 28), end_date=date(2016,  2, 24), weeks_in_month=4)\n",
        "    , Row(sequence_id=1, cal_year=2016, cal_month=3,  start_date=date(2016,  2, 25), end_date=date(2016,  3, 30), weeks_in_month=5)\n",
        "    , Row(sequence_id=1, cal_year=2016, cal_month=4,  start_date=date(2016,  3, 31), end_date=date(2016,  4, 27), weeks_in_month=4)\n",
        "    , Row(sequence_id=1, cal_year=2016, cal_month=5,  start_date=date(2016,  4, 28), end_date=date(2016,  6,  1), weeks_in_month=5)\n",
        "    , Row(sequence_id=1, cal_year=2016, cal_month=6,  start_date=date(2016,  6,  2), end_date=date(2016,  6, 29), weeks_in_month=4)\n",
        "    , Row(sequence_id=1, cal_year=2016, cal_month=7,  start_date=date(2016,  6, 30), end_date=date(2016,  7, 27), weeks_in_month=4)\n",
        "    , Row(sequence_id=1, cal_year=2016, cal_month=8,  start_date=date(2016,  7, 28), end_date=date(2016,  8, 31), weeks_in_month=5)\n",
        "    , Row(sequence_id=1, cal_year=2016, cal_month=9,  start_date=date(2016,  9,  1), end_date=date(2016,  9, 28), weeks_in_month=4)\n",
        "    , Row(sequence_id=1, cal_year=2016, cal_month=10, start_date=date(2016,  9, 29), end_date=date(2016, 10, 26), weeks_in_month=4)\n",
        "    , Row(sequence_id=1, cal_year=2016, cal_month=11, start_date=date(2016, 10, 27), end_date=date(2016, 11, 30), weeks_in_month=5)\n",
        "    , Row(sequence_id=1, cal_year=2016, cal_month=12, start_date=date(2016, 12,  1), end_date=date(2016, 12, 28), weeks_in_month=4)\n",
        "    # 2017\n",
        "    , Row(sequence_id=1, cal_year=2017, cal_month=1,  start_date=date(2016, 12, 29), end_date=date(2017,  1, 25), weeks_in_month=4)\n",
        "    , Row(sequence_id=1, cal_year=2017, cal_month=2,  start_date=date(2017,  1, 26), end_date=date(2017,  2, 22), weeks_in_month=4)\n",
        "    , Row(sequence_id=1, cal_year=2017, cal_month=3,  start_date=date(2017,  2, 23), end_date=date(2017,  3, 29), weeks_in_month=5)\n",
        "    , Row(sequence_id=1, cal_year=2017, cal_month=4,  start_date=date(2017,  3, 30), end_date=date(2017,  4, 26), weeks_in_month=4)\n",
        "    , Row(sequence_id=1, cal_year=2017, cal_month=5,  start_date=date(2017,  4, 27), end_date=date(2017,  5, 31), weeks_in_month=5)\n",
        "    , Row(sequence_id=1, cal_year=2017, cal_month=6,  start_date=date(2017,  6,  1), end_date=date(2017,  6, 28), weeks_in_month=4)\n",
        "    , Row(sequence_id=1, cal_year=2017, cal_month=7,  start_date=date(2017,  6, 29), end_date=date(2017,  7, 26), weeks_in_month=4)\n",
        "    , Row(sequence_id=1, cal_year=2017, cal_month=8,  start_date=date(2017,  7, 27), end_date=date(2017,  8, 30), weeks_in_month=5)\n",
        "    , Row(sequence_id=1, cal_year=2017, cal_month=9,  start_date=date(2017,  8, 31), end_date=date(2017,  9, 27), weeks_in_month=4)\n",
        "    , Row(sequence_id=1, cal_year=2017, cal_month=10, start_date=date(2017,  9, 28), end_date=date(2017, 10, 25), weeks_in_month=4)\n",
        "    , Row(sequence_id=1, cal_year=2017, cal_month=11, start_date=date(2017, 10, 26), end_date=date(2017, 11, 29), weeks_in_month=5)\n",
        "    , Row(sequence_id=1, cal_year=2017, cal_month=12, start_date=date(2017, 11, 30), end_date=date(2017, 12, 27), weeks_in_month=4)\n",
        "    # 2018\n",
        "    , Row(sequence_id=1, cal_year=2018, cal_month=1,  start_date=date(2017, 12, 28), end_date=date(2018,  1, 24), weeks_in_month=4)\n",
        "    , Row(sequence_id=1, cal_year=2018, cal_month=2,  start_date=date(2018,  1, 25), end_date=date(2018,  2, 21), weeks_in_month=4)\n",
        "    , Row(sequence_id=1, cal_year=2018, cal_month=3,  start_date=date(2018,  2, 22), end_date=date(2018,  3, 28), weeks_in_month=5)\n",
        "    , Row(sequence_id=1, cal_year=2018, cal_month=4,  start_date=date(2018,  3, 29), end_date=date(2018,  4, 25), weeks_in_month=4)\n",
        "    , Row(sequence_id=1, cal_year=2018, cal_month=5,  start_date=date(2018,  4, 26), end_date=date(2018,  5, 30), weeks_in_month=5)\n",
        "    , Row(sequence_id=1, cal_year=2018, cal_month=6,  start_date=date(2018,  5, 31), end_date=date(2018,  6, 27), weeks_in_month=4)\n",
        "    , Row(sequence_id=1, cal_year=2018, cal_month=7,  start_date=date(2018,  6, 28), end_date=date(2018,  7, 25), weeks_in_month=4)\n",
        "    , Row(sequence_id=1, cal_year=2018, cal_month=8,  start_date=date(2018,  7, 26), end_date=date(2018,  8, 29), weeks_in_month=5)\n",
        "    , Row(sequence_id=1, cal_year=2018, cal_month=9,  start_date=date(2018,  8, 30), end_date=date(2018,  9, 26), weeks_in_month=4)\n",
        "    , Row(sequence_id=1, cal_year=2018, cal_month=10, start_date=date(2018,  9, 27), end_date=date(2018, 10, 24), weeks_in_month=4)\n",
        "    , Row(sequence_id=1, cal_year=2018, cal_month=11, start_date=date(2018, 10, 25), end_date=date(2018, 11, 28), weeks_in_month=5)\n",
        "    , Row(sequence_id=1, cal_year=2018, cal_month=12, start_date=date(2018, 11, 29), end_date=date(2018, 12, 26), weeks_in_month=4)\n",
        "    #2019\n",
        "    , Row(sequence_id=1, cal_year=2019, cal_month=1,  start_date=date(2019,  1, 3), end_date=date(2019,  1, 30), weeks_in_month=4)\n",
        "    , Row(sequence_id=1, cal_year=2019, cal_month=2,  start_date=date(2019,  1, 31), end_date=date(2019,  2, 27), weeks_in_month=4)\n",
        "    , Row(sequence_id=1, cal_year=2019, cal_month=3,  start_date=date(2019,  2, 28), end_date=date(2019,  3, 27), weeks_in_month=5)\n",
        "    , Row(sequence_id=1, cal_year=2019, cal_month=4,  start_date=date(2019,  3, 28), end_date=date(2019,  5, 1), weeks_in_month=4)\n",
        "    , Row(sequence_id=1, cal_year=2019, cal_month=5,  start_date=date(2019,  5, 2), end_date=date(2019,  5, 29), weeks_in_month=5)\n",
        "    , Row(sequence_id=1, cal_year=2019, cal_month=6,  start_date=date(2019,  5, 30), end_date=date(2019,  6, 26), weeks_in_month=4)\n",
        "    , Row(sequence_id=1, cal_year=2019, cal_month=7,  start_date=date(2019,  6, 27), end_date=date(2019,  7, 31), weeks_in_month=4)\n",
        "    , Row(sequence_id=1, cal_year=2019, cal_month=8,  start_date=date(2019,  8, 1), end_date=date(2019,  8, 28), weeks_in_month=5)\n",
        "    , Row(sequence_id=1, cal_year=2019, cal_month=9,  start_date=date(2019,  8, 29), end_date=date(2019,  9, 25), weeks_in_month=4)\n",
        "    , Row(sequence_id=1, cal_year=2019, cal_month=10, start_date=date(2019,  9, 26), end_date=date(2019, 10, 30), weeks_in_month=4)\n",
        "    , Row(sequence_id=1, cal_year=2019, cal_month=11, start_date=date(2019, 10, 31), end_date=date(2019, 11, 27), weeks_in_month=5)\n",
        "    , Row(sequence_id=1, cal_year=2019, cal_month=12, start_date=date(2019, 11, 28), end_date=date(2020, 1, 1), weeks_in_month=4)\n",
        "    #2020\n",
        "    , Row(sequence_id=1, cal_year=2020, cal_month=1,  start_date=date(2020,  1, 2), end_date=date(2020,  1, 29), weeks_in_month=4)\n",
        "    , Row(sequence_id=1, cal_year=2020, cal_month=2,  start_date=date(2020,  1, 30), end_date=date(2020,  2, 26), weeks_in_month=4)\n",
        "    , Row(sequence_id=1, cal_year=2020, cal_month=3,  start_date=date(2020,  2, 27), end_date=date(2020,  4, 1), weeks_in_month=5)\n",
        "    , Row(sequence_id=1, cal_year=2020, cal_month=4,  start_date=date(2020,  4, 2), end_date=date(2020,  4, 29), weeks_in_month=4)\n",
        "    , Row(sequence_id=1, cal_year=2020, cal_month=5,  start_date=date(2020,  4, 30), end_date=date(2020,  5, 27), weeks_in_month=4)\n",
        "    , Row(sequence_id=1, cal_year=2020, cal_month=6,  start_date=date(2020,  5, 28), end_date=date(2020,  7, 1), weeks_in_month=5)\n",
        "    , Row(sequence_id=1, cal_year=2020, cal_month=7,  start_date=date(2020,  7, 2), end_date=date(2020,  8, 26), weeks_in_month=8)\n",
        "    , Row(sequence_id=1, cal_year=2020, cal_month=8,  start_date=date(2020,  8, 27), end_date=date(2020,  9, 30), weeks_in_month=5)\n",
        "    , Row(sequence_id=1, cal_year=2020, cal_month=9,  start_date=date(2020,  10, 1), end_date=date(2020, 10, 28), weeks_in_month=4)\n",
        "    , Row(sequence_id=1, cal_year=2020, cal_month=10, start_date=date(2020,  10, 29), end_date=date(2020, 12, 30), weeks_in_month=9)\n",
        "     #2021\n",
        "    , Row(sequence_id=1, cal_year=2021, cal_month=1,  start_date=date(2020, 12, 31), end_date=date(2021, 2, 17), weeks_in_month=6)\n",
        "    , Row(sequence_id=1, cal_year=2021, cal_month=2,  start_date=date(2021,  2, 18), end_date=date(2021,  3, 31), weeks_in_month=6)\n",
        "    , Row(sequence_id=1, cal_year=2021, cal_month=3,  start_date=date(2021,  4, 1), end_date=date(2021,  4, 28), weeks_in_month=4)\n",
        "    , Row(sequence_id=1, cal_year=2021, cal_month=4,  start_date=date(2021,  4, 29), end_date=date(2021,  5, 26), weeks_in_month=4)\n",
        "    , Row(sequence_id=1, cal_year=2021, cal_month=5,  start_date=date(2021,  5, 27), end_date=date(2021,  6, 30), weeks_in_month=5)\n",
        "    , Row(sequence_id=1, cal_year=2021, cal_month=6,  start_date=date(2021,  7, 1), end_date=date(2021,  7, 28), weeks_in_month=5)\n",
        "    , Row(sequence_id=1, cal_year=2021, cal_month=7,  start_date=date(2021,  7, 29), end_date=date(2021,  8, 25), weeks_in_month=4)\n",
        "    , Row(sequence_id=1, cal_year=2021, cal_month=8,  start_date=date(2021,  8, 26), end_date=date(2021,  9, 29), weeks_in_month=5)\n",
        "    , Row(sequence_id=1, cal_year=2021, cal_month=9,  start_date=date(2021,  9, 30), end_date=date(2021, 10, 27), weeks_in_month=4)\n",
        "    , Row(sequence_id=1, cal_year=2021, cal_month=10, start_date=date(2021,  10, 28), end_date=date(2021, 12, 29), weeks_in_month=9)\n",
        "    ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": [
        "%pyspark\n",
        "\n",
        "def init_pc_df(pc_data):\n",
        "\n",
        "    print (\"Creating pc_df\")\n",
        "    pc_df = sqlContext.createDataFrame(pc_data)\n",
        "    pc_df.cache()\n",
        "\n",
        "    return pc_df\n",
        "    \n",
        "def get_pc_df():\n",
        "\n",
        "    print (\"Creating pc_df\")\n",
        "    pc_df = sqlContext.createDataFrame(pc_data)\n",
        "    pc_df.cache()\n",
        "\n",
        "    return pc_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": [
        "%pyspark\n",
        "\n",
        "def init_ad_promo_mc_df(ad_promo_mc_data):\n",
        "\n",
        "    print (\"Creating ad_promo_mc_df\")\n",
        "    ad_promo_mc_df = sqlContext.createDataFrame(ad_promo_mc_data)\n",
        "    ad_promo_mc_df.cache()\n",
        "\n",
        "    return ad_promo_mc_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": [
        "%pyspark\n",
        "\n",
        "# Initialize/load AAP period calendar\n",
        "pc_df = init_pc_df(pc_data)\n",
        "\n",
        "# Initialize AAP ad promo monthly calendar\n",
        "ad_promo_mc_df = init_ad_promo_mc_df(ad_promo_mc_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": [
        "%pyspark\n",
        "\n",
        "def load_sales_details(daily_changes=False, as_of_date=None):\n",
        "        \"\"\" Load sales details from configured data store\n",
        "\n",
        "            if daily_changes = True ; Will load the sales data of maximum processed dttm\n",
        "\n",
        "            Else False ; Will load complete sales data\n",
        "\n",
        "            Initially set to false, if load_sales_details(True) is called then sales data of maximum processed dttm is loaded\n",
        "\n",
        "        Returns:\n",
        "            rdd (RDD) : RDD (sales transaction level details) loaded from the data source.\n",
        "\n",
        "        \"\"\"\n",
        "        if daily_changes:\n",
        "            #data_filter = \"and csdate between '2018-07-21' and '2018-07-30'\"\n",
        "\n",
        "            df_csdates = sqlContext.sql(\"select distinct csdate from \" + sales_details_table_name + \\\n",
        "                                             \" where date(processed_dttm) = (select date(max(processed_dttm)) from \" + sales_details_table_name + \")\")\n",
        "\n",
        "            csdates_rdd = df_csdates.rdd.collect()\n",
        "\n",
        "            csdates = []\n",
        "            for row in csdates_rdd:\n",
        "                csdates.append(\"'\" + str(row.csdate) + \"'\")\n",
        "\n",
        "            csdates_list = ','.join(csdates)\n",
        "\n",
        "            data_filter = \" and csdate in (\" + csdates_list + \")\"\n",
        "        else:\n",
        "            if as_of_date:\n",
        "                csdates = []\n",
        "\n",
        "                for i in as_of_date:\n",
        "                    csdates.append(\"'\" + str(i) + \"'\")\n",
        "\n",
        "                csdates_list = ','.join(csdates)\n",
        "\n",
        "                data_filter = \" and csdate in (\" + csdates_list + \")\"\n",
        "            else:\n",
        "                data_filter = \"\"\n",
        "\n",
        "        sqlContext.sql(\"use \" + sales_details_db_name)\n",
        "        # Consider only records which has csdtyp 01,04,11,21\n",
        "        tran = sqlContext.sql(\"select * from \" + sales_details_table_name + \" where csityp in (11,12) and csdsts = 0 \" + data_filter)\n",
        "\n",
        "        # Data for DIY ecommerce transactions\n",
        "        ecom_tran = sqlContext.sql(\"select * from \" + sales_details_table_name + \\\n",
        "                                        \" where csdsts = 0 and csstor = 1020 and csityp in (11,12) and csostr is not null and csostr != 0 \" + data_filter)\n",
        "\n",
        "        ecom_tran.show()\n",
        "\n",
        "        ecom_tran.createOrReplaceTempView(\"ecom_tran\")\n",
        "\n",
        "        ecom_tran_modify = sqlContext.sql(\"SELECT store_rk,sku_rk,date_rk \\\n",
        "                                                                      ,csostr AS csstor \\\n",
        "                                                                      ,cscen,csreg,csroll,cstran,csseq \\\n",
        "                                                                      ,csdtyp \\\n",
        "                                                                      ,cssku,csretl,cscost \\\n",
        "                                                                      ,csqty,csexpr,csexcs,csdsts \\\n",
        "                                                                      ,cspovr,cstil,csupc,csexvt \\\n",
        "                                                                      ,csvexm,csityp,csexds,csrgpr \\\n",
        "                                                                      ,csrstp,csdrsn,csosls,csostr \\\n",
        "                                                                      ,csocen,csodat,cspspr,csddoc \\\n",
        "                                                                      ,csscan,csatyp,csacct,csprtp \\\n",
        "                                                                      ,csscur,cstcur,cstrat,cstmd \\\n",
        "                                                                      ,cstrtl,cstrpr,cstppr,cstcst \\\n",
        "                                                                      ,cstxpr,cstxcs,cstxvt,cstxds \\\n",
        "                                                                      ,csoreg,csotrn,csprcd,cssdlc \\\n",
        "                                                                      ,cspcmp,cscevt,load_id,processed_dttm \\\n",
        "                                                                      ,invoice_year,invoice_period,csdate FROM ecom_tran\")\n",
        "\n",
        "        return tran.unionAll(ecom_tran_modify)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": [
        "%pyspark\n",
        "\n",
        "load_sales_test = load_sales_details()\n",
        "load_sales_test.show(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": [
        "%pyspark\n",
        "\n",
        "def load_cq_sales_details(daily_changes=False):\n",
        "        \"\"\" Load sales details from configured data store\n",
        "\n",
        "            if daily_changes = True ; Will load the sales data of maximum processed dttm\n",
        "\n",
        "            Else False ; Will load complete sales data\n",
        "\n",
        "            Initially set to false, if load_sales_details(True) is called then sales data of maximum processed dttm is loaded\n",
        "\n",
        "        Returns:\n",
        "            rdd (RDD) : RDD (sales transaction level details) loaded from the data source.\n",
        "\n",
        "        \"\"\"\n",
        "        if daily_changes:\n",
        "            #data_filter = \"and csdate between '2018-09-01' and '2018-10-30'\"\n",
        "\n",
        "            df_csdates = sqlContext.sql(\"select distinct cast(csdate as date) from \" + sales_details_table_name + \\\n",
        "                                             \" where processed_dttm = (select max(processed_dttm) from \" + sales_details_table_name + \")\")\n",
        "\n",
        "            csdates_rdd = df_csdates.rdd.collect()\n",
        "\n",
        "            csdates = []\n",
        "            for row in csdates_rdd:\n",
        "                csdates.append(\"'\" + str(row.csdate) + \"'\")\n",
        "\n",
        "            csdates_list = ','.join(csdates)\n",
        "\n",
        "            data_filter = \" and cast(csdate as date) in (\" + csdates_list + \")\"\n",
        "\n",
        "        else:\n",
        "\n",
        "            data_filter = \"\"\n",
        "\n",
        "        df_exploris = sqlContext.sql('select * from '+sales_details_table_name)\n",
        "        df_exploris = df_exploris.withColumn(\"csdate\", df_exploris[\"csdate\"].cast(\"date\"))\n",
        "        df_exploris.createOrReplaceTempView('df_exploris')\n",
        "    \n",
        "        # Consider only records which has csdtyp 01,04,11,21\n",
        "        tran = sqlContext.sql(\"select * from df_exploris where csityp in (11,12) and csdsts = 0 \" + data_filter)\n",
        "\n",
        "        return tran"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": [
        "%pyspark\n",
        "\n",
        "load_test = load_cq_sales_details()\n",
        "load_test.show(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": [
        "%pyspark\n",
        "\n",
        "def load_sales_header():\n",
        "        \"\"\" Load sales details from configured data store\n",
        "\n",
        "        Returns:\n",
        "            rdd (RDD) : RDD (sales transaction level details) loaded from the data source.\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        sqlContext.sql(\"use \" + sales_details_db_name)\n",
        "        return sqlContext.sql(\"select * from \" + sales_header_table_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": [
        "%pyspark\n",
        "\n",
        "def load_store_sales_by_period():\n",
        "        sqlContext.sql(\"use \" + store_sales_by_period_db_name)\n",
        "        return sqlContext.sql(\"select * from \" + store_sales_by_period_table_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": [
        "%pyspark\n",
        "\n",
        "def drop_sales_details_with_0_quantity(df):\n",
        "        \"\"\" Transformation to filter un-necessary/irrelavent sales\n",
        "\n",
        "        Args:\n",
        "            df (DataFrame) : DataFrame (sales transaction level details) to filter.\n",
        "\n",
        "        Returns:\n",
        "            rdd (DataFrame) : Filtered DataFrame\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": [
        "%pyspark\n",
        "\n",
        "def get_store_sales_by_period(df):\n",
        "\n",
        "        \"\"\" Transformation to compute cy, py, ppy aggregates\n",
        "\n",
        "        Args:\n",
        "            df (DataFrame) : DataFrame (sales store,sku level details) to transform.\n",
        "\n",
        "        Returns:\n",
        "            df (DataFrame) : Transformed DataFrame\n",
        "\n",
        "        \"\"\"\n",
        "        df=df.withColumn(\"customer_type\",when(df.csacct == ' ', 'DIY').otherwise('DIFM'))\n",
        "        #df.printSchema()\n",
        "        df=df.withColumnRenamed(\"csstor\",\"store_number\").withColumnRenamed(\"cssku\", \"sku_number\").withColumnRenamed(\"invoice_year\", \"fiscal_year\").withColumnRenamed(\"invoice_period\", \"fiscal_period\")\n",
        "        #df=df.withColumnRenamed(\"store_number_cq\",\"store_number\").withColumnRenamed(\"sku_number_cq\", \"sku_number\").withColumnRenamed(\"invoice_year\", \"fiscal_year\").withColumnRenamed(\"invoice_period\", \"fiscal_period\")\n",
        "        #df.printSchema()\n",
        "        #remove conditions on csdtyp | use csityp instead of csdtyp everywhere in code\n",
        "        ssbp = df.groupby(\"store_number\"\n",
        "                       , \"sku_number\"\n",
        "                       , \"fiscal_year\"\n",
        "                       , \"fiscal_period\"\n",
        "                       , \"customer_type\"\n",
        "                       ).agg(sum(col(\"csqty\")).alias(\"qty_sold\")\n",
        "                             ,sum(col(\"csexpr\")).alias(\"gross_sales\")\n",
        "                             ,sum(col(\"csqty\") * col(\"cscost\")).alias(\"sales_cost\")\n",
        "                             )\n",
        "        #\n",
        "\n",
        "        \"\"\"agg(sum(when(((df.csdtyp == '01') | (df.csdtyp == '04') | (df.csdtyp == '11') | (df.csdtyp == '21')), col(\"csqty\")).\n",
        "                                      otherwise(0)).alias(\"qty_sold\")\n",
        "                             ,sum(when(((df.csdtyp == '01') | (df.csdtyp == '04') | (df.csdtyp == '11') | (df.csdtyp == '21')), col(\"csexpr\")).\n",
        "                                 otherwise(0)).alias(\"gross_sales\")\n",
        "                             , sum(when(((df.csdtyp == '01') | (df.csdtyp == '04') | (df.csdtyp == '11') | (df.csdtyp == '21')), col(\"csqty\") * col(\"cscost\")).\n",
        "                                   otherwise(0)).alias(\"sales_cost\")\n",
        "                             )\"\"\"\n",
        "\n",
        "        return ssbp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": [
        "%pyspark\n",
        "\n",
        "def agg_sales_by_store_sku_daily_sales(df_sales):\n",
        "\n",
        "        \"\"\" Transformation to aggregate sales by store, sku based on daily basis of processed_dttm\n",
        "\n",
        "                Args:\n",
        "                        df_sales_last_processed (DataFrame) : DataFrame (sales transaction level details) to transform.\n",
        "\n",
        "                        Returns:\n",
        "                            df_daily_sales (DataFrame) : Transformed DataFrame\n",
        "\n",
        "            \"\"\"\n",
        "\n",
        "        df_agg_daily_sales = df_sales.groupBy(\"date_rk\",\n",
        "                                                  \"csstor\",\n",
        "                                                  \"cssku\",\n",
        "                                                  \"csdate\",\n",
        "                                                  \"invoice_period\",\n",
        "                                                  \"invoice_year\").agg(sum(col('csqty')).alias('qty_sold'),\n",
        "                                                                      sum(col('csexpr')).alias('sales_price'),\n",
        "                                                                      sum(col(\"csqty\") * col(\"cscost\")).alias(\n",
        "                                                                          'sales_cost'))\n",
        "\n",
        "        df_agg_daily_sales.createOrReplaceTempView(\"df_agg_daily_sales\")\n",
        "\n",
        "        df_sku_master = sqlContext.sql(\"select skunum, sku_rk,valid_end_dttm from \" + sku_master_table_name + \\\n",
        "                                            \" where valid_end_dttm = '9999-12-31 00:00:00'\")\n",
        "        df_sku_master.createOrReplaceTempView(\"df_sku_master\")\n",
        "\n",
        "        df_sku_master_join_agg_sales = sqlContext.sql(\"select B.sku_rk, A.cssku, A.csstor, A.qty_sold, A.date_rk, A.sales_price, A.sales_cost, A.invoice_period, A.invoice_year,A.csdate \\\n",
        "                                                                from df_agg_daily_sales A left join df_sku_master B on A.cssku = B.skunum\")\n",
        "\n",
        "        df_sku_master_join_agg_sales.createOrReplaceTempView(\"df_sku_master_join_agg_sales\")\n",
        "\n",
        "        df_store_master = sqlContext.sql(\"select storenum, store_rk, valid_end_dttm from \" + store_master_table_name +\n",
        "                                              \" where valid_end_dttm = '9999-12-31 00:00:00' \")\n",
        "        df_store_master.createOrReplaceTempView(\"df_store_master\")\n",
        "\n",
        "        df_store_master_join_agg_sales = sqlContext.sql(\"select B.store_rk,A.csstor, A.sku_rk, A.date_rk, A.cssku, A.qty_sold, A.sales_price, A.sales_cost, A.invoice_period, A.invoice_year,A.csdate \\\n",
        "                                                                  from df_sku_master_join_agg_sales A left join df_store_master B on A.csstor = B.storenum \")\n",
        "\n",
        "        df_store_master_join_agg_sales.createOrReplaceTempView(\"df_store_master_join_agg_sales\")\n",
        "\n",
        "        df_daily_sales = sqlContext.sql(\"select cast(store_rk as bigint), \\\n",
        "                                                         cast(sku_rk as bigint), \\\n",
        "                                                         cast(date_rk as bigint), \\\n",
        "                                                         cast(csstor as bigint), \\\n",
        "                                                         cast(cssku as decimal(20,0)), \\\n",
        "                                                         cast(qty_sold as decimal(22,3)), \\\n",
        "                                                         cast(sales_price as decimal(25,2)), \\\n",
        "                                                         cast(sales_cost as decimal(25,4)), \\\n",
        "                                                         cast(invoice_year as int), \\\n",
        "                                                         cast(invoice_period as int), \\\n",
        "                                                         csdate from df_store_master_join_agg_sales\")\n",
        "\n",
        "        return df_daily_sales"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": [
        "%pyspark\n",
        "\n",
        "def agg_sales_by_store_sku_weekly(df_sales_data, full_refresh=True):\n",
        "\n",
        "        df_cal_hierarchy = sqlContext.sql(\"select dfyr, dwoy, dgdt, dper from \" + cal_hierarchy_table_name)\n",
        "        df_cal_hierarchy.cache()\n",
        "        df_cal_hierarchy.createOrReplaceTempView(\"df_cal_hierarchy\")\n",
        "\n",
        "        if full_refresh:\n",
        "            df = sqlContext.sql(\"select * from \" + daily_sales_store_sku)\n",
        "            df.createOrReplaceTempView(\"df\")\n",
        "\n",
        "        else:\n",
        "            df_sales_data.createOrReplaceTempView(\"df_sales_data\")\n",
        "\n",
        "            df_csdates = sqlContext.sql(\"select distinct csdate from df_sales_data\")\n",
        "\n",
        "            df_csdates.createOrReplaceTempView(\"df_csdates\")\n",
        "            daily_csdates_rdd = df_csdates.rdd.collect()\n",
        "            daily_csdates = []\n",
        "            for row in daily_csdates_rdd:\n",
        "                daily_csdates.append(\"'\" + str(row.csdate) + \"'\")\n",
        "\n",
        "            daily_csdates_list = ','.join(daily_csdates)\n",
        "\n",
        "            daily_date_filter = \"(\" + daily_csdates_list + \")\"\n",
        "\n",
        "            df_get_yr_woy = sqlContext.sql(\n",
        "                    \"select distinct dfyr, dwoy from df_cal_hierarchy where dgdt in \" + daily_date_filter)\n",
        "\n",
        "            rdd_yr_woy = df_get_yr_woy.rdd.collect()\n",
        "\n",
        "            df_weekly_dates = None\n",
        "\n",
        "            for row in rdd_yr_woy:\n",
        "                df_dates = sqlContext.sql(\n",
        "                        \"select dgdt from df_cal_hierarchy where dfyr = \" + str(row['dfyr']) + \" and dwoy = \" + str(\n",
        "                            row['dwoy']))\n",
        "                if df_weekly_dates:\n",
        "                    df_weekly_dates = df_weekly_dates.union(df_dates)\n",
        "                else:\n",
        "                    df_weekly_dates = df_dates\n",
        "\n",
        "            df_weekly_dates.show(50)\n",
        "\n",
        "            df_week_dates = df_weekly_dates.rdd.collect()\n",
        "            weekly_csdates = []\n",
        "            for row in df_week_dates:\n",
        "                weekly_csdates.append(\"'\" + str(row.dgdt) + \"'\")\n",
        "\n",
        "                weekly_csdates_list = ','.join(weekly_csdates)\n",
        "\n",
        "                weekly_date_filter = \"(\" + weekly_csdates_list + \")\"\n",
        "\n",
        "            df = sqlContext.sql(\"select * from \" + daily_sales_store_sku + \" where csdate in \" + weekly_date_filter)\n",
        "            df.createOrReplaceTempView(\"df\")\n",
        "\n",
        "        df_weekly = sqlContext.sql(\"select B.dper, B.dwoy, A.store_rk,A.csstor, A.sku_rk, A.cssku, A.qty_sold, A.sales_price, A.sales_cost, A.invoice_period, A.invoice_year,A.csdate \\\n",
        "                                             from df A left join df_cal_hierarchy B on A.csdate = B.dgdt\")\n",
        "\n",
        "        df_weekly_sales = df_weekly.groupBy(\"store_rk\",\n",
        "                                                \"sku_rk\",\n",
        "                                                \"csstor\",\n",
        "                                                \"cssku\",\n",
        "                                                \"dwoy\",\n",
        "                                                \"dper\",\n",
        "                                                \"invoice_period\",\n",
        "                                                \"invoice_year\").agg(sum(col('qty_sold')).alias('qty_sold'),\n",
        "                                                            sum(col('sales_price')).alias('sales_price'),\n",
        "                                                            sum(col('sales_cost')).alias('sales_cost'))\n",
        "\n",
        "        df_weekly_sales.createOrReplaceTempView(\"df_weekly_sales\")\n",
        "\n",
        "        df_final_weekly_sales = sqlContext.sql(\"select cast(store_rk as int), \\\n",
        "                                                                  cast(sku_rk as int),\\\n",
        "                                                                  cast(csstor as int) storenum, \\\n",
        "                                                                  cast(cssku as bigint) skunum, \\\n",
        "                                                                  cast(dper as tinyint), \\\n",
        "                                                                  cast(qty_sold as decimal(31,3)), \\\n",
        "                                                                  cast(sales_price as decimal(34,2)), \\\n",
        "                                                                  cast(sales_cost as decimal(34,4)), \\\n",
        "                                                                  cast(invoice_year as smallint) dfyr, \\\n",
        "                                                                  cast(invoice_period as tinyint), \\\n",
        "                                                                  cast(dwoy as tinyint) from df_weekly_sales \")\n",
        "\n",
        "        return df_final_weekly_sales"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": [
        "%pyspark\n",
        "\n",
        "def agg_sales_by_sku_weekly(df_agg_sales_by_store_sku_weekly = None):\n",
        "\n",
        "        sqlContext.sql(\"msck repair table \" + agg_sales_weekly_store_sku)\n",
        "\n",
        "        if df_agg_sales_by_store_sku_weekly:\n",
        "            df = df_agg_sales_by_store_sku_weekly\n",
        "        else:\n",
        "            df = sqlContext.sql(\"select * from \" + agg_sales_weekly_store_sku)\n",
        "\n",
        "        df_weekly_sales_by_sku = df.groupBy(\"sku_rk\",\n",
        "                                            \"skunum\",\n",
        "                                            \"dwoy\",\n",
        "                                            \"dper\",\n",
        "                                            \"invoice_period\",\n",
        "                                            \"dfyr\").agg(sum(col('qty_sold')).alias('qty_sold'),\n",
        "                                                            sum(col('sales_price')).alias('sales_price'),\n",
        "                                                            sum(col('sales_cost')).alias('sales_cost'))\n",
        "\n",
        "        return df_weekly_sales_by_sku\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": [
        "%pyspark\n",
        "\n",
        "def agg_sales_by_store_sku_ad_promo_monthly(dates=[]):\n",
        "\n",
        "        df_ad_promo_mc = get_ad_promo_mc_df()\n",
        "\n",
        "        ad_promo_cal = []\n",
        "\n",
        "        for row in df_ad_promo_mc.rdd.collect():\n",
        "            date = row.start_date\n",
        "            while (date <= row.end_date):\n",
        "                ad_promo_cal.append(Row(date=date, cal_year=row.cal_year, cal_month=row.cal_month))\n",
        "                date = date + timedelta(days=1)\n",
        "\n",
        "        df_promo_cal = sqlContext.createDataFrame(ad_promo_cal)\n",
        "\n",
        "        df_promo_cal.createOrReplaceTempView(\"df_promo_cal\")\n",
        "\n",
        "        df = sqlContext.sql(\"select A.store_rk, \\\n",
        "                                         A.sku_rk,\\\n",
        "                                         A.csstor, \\\n",
        "                                         A.cssku, \\\n",
        "                                         A.qty_sold, \\\n",
        "                                         A.sales_price, \\\n",
        "                                         A.sales_cost, \\\n",
        "                                         B.cal_year, \\\n",
        "                                         B.cal_month from \" + daily_sales_store_sku + \" A left join df_promo_cal B on A.csdate=B.date\")\n",
        "\n",
        "        if dates != []:\n",
        "\n",
        "            print (\"Filtering on months based on dates\")\n",
        "            df.createOrReplaceTempView(\"df\")\n",
        "\n",
        "            as_of_date = []\n",
        "            for each_date in dates:\n",
        "                as_of_date.append(\"'\" + str(each_date) + \"'\")\n",
        "\n",
        "            csdates_list = ','.join(as_of_date)\n",
        "\n",
        "            date_filter = \" date in (\" + csdates_list + \")\"\n",
        "\n",
        "            print(date_filter)\n",
        "\n",
        "            df_filter_year_month_cal = sqlContext.sql(\n",
        "                \"select distinct cal_year as year, cal_month as month from df_promo_cal where \" + date_filter)\n",
        "\n",
        "            df_filter_year_month_cal.createOrReplaceTempView(\"df_filter_year_month_cal\")\n",
        "\n",
        "            df = sqlContext.sql(\n",
        "                \"select A.csstor, A.cssku, A.qty_sold, A.sales_price, A.sales_cost, A.cal_year, A.cal_month from df A join df_filter_year_month_cal B on A.cal_year=B.year and A.cal_month=B.month\")\n",
        "            df.createOrReplaceTempView(\"df\")\n",
        "            df_filtered = sqlContext.sql(\"select distinct cal_year, cal_month from df\")\n",
        "            df_filtered.show()\n",
        "\n",
        "        print(\"Computing ETL...\")\n",
        "        df_agg_ad_promo_monthly_sales = df.groupBy(\"store_rk\",\n",
        "                                                   \"sku_rk\",\n",
        "                                                   \"csstor\",\n",
        "                                                   \"cssku\",\n",
        "                                                   \"cal_year\",\n",
        "                                                   \"cal_month\").agg(sum(col(\"qty_sold\")).alias(\"qty_sold\")\n",
        "                                                                  , sum(col(\"sales_price\")).alias(\"sales_price\")\n",
        "                                                                  , sum(col(\"sales_cost\")).alias(\"sales_cost\"))\n",
        "\n",
        "        df_agg_ad_promo_monthly_sales.createOrReplaceTempView(\"df_final_ad_promo_monthly_sales\")\n",
        "\n",
        "        df_sku_base_product_group = sqlContext.sql(\"select sku_number,merchandise_group_desc from \" + sku_prodgrp_table_name)\n",
        "        df_sku_base_product_group.createOrReplaceTempView(\"df_sku_base_product_group\")\n",
        "\n",
        "        df_sku_base_product_join = sqlContext.sql(\"select A.store_rk, A.sku_rk, A.csstor, A.cssku, A.qty_sold, A.sales_price, A.sales_cost, A.cal_year, A.cal_month, B.merchandise_group_desc \\\n",
        "                                                                  from df_final_ad_promo_monthly_sales A left join df_sku_base_product_group B \\\n",
        "                                                                       on A.cssku = B.sku_number\")\n",
        "\n",
        "        df_sku_base_product_join.createOrReplaceTempView(\"df_final_ad_promo_sales\")\n",
        "\n",
        "        df_ad_promo_monthly_sales_by_store_sku = sqlContext.sql(\"select cast(store_rk as int), \\\n",
        "                                                                       cast(sku_rk as int), \\\n",
        "                                                                       cast(csstor as bigint) stornum, \\\n",
        "                                                                       cast(cssku as bigint) skunum, \\\n",
        "                                                                       cast(qty_sold as decimal(31,3)),\\\n",
        "                                                                       cast(sales_price as decimal(34,2)), \\\n",
        "                                                                       cast(sales_cost as decimal(34,4)),\\\n",
        "                                                                       cast (cal_year as smallint) year, \\\n",
        "                                                                       cast (cal_month as tinyint) month,\\\n",
        "                                                                       cast (merchandise_group_desc as varchar(50))  \\\n",
        "                                                                       from df_final_ad_promo_sales \")\n",
        "\n",
        "        return df_ad_promo_monthly_sales_by_store_sku"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": [
        "%pyspark\n",
        "\n",
        "def agg_sales_by_sku_ad_promo_monthly(dates=[]):\n",
        "\n",
        "        \"\"\" Transformation to aggregate sales by sku based on promo monthly calendar\n",
        "\n",
        "                Args:\n",
        "                    df (DataFrame) : DataFrame (sales transaction level details) to transform.\n",
        "\n",
        "                Returns:\n",
        "                    df_ad_promo_monthly_sales (DataFrame) : Transformed DataFrame\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "\t    # print(dates)\n",
        "\n",
        "        # invoice_cshdet.createOrReplaceTempView(\"invoice_cshdet\")\n",
        "\n",
        "        df_ad_promo_mc = get_ad_promo_mc_df()\n",
        "\n",
        "        ad_promo_cal = []\n",
        "\n",
        "        for row in df_ad_promo_mc.rdd.collect():\n",
        "            date = row.start_date\n",
        "            while (date <= row.end_date):\n",
        "                ad_promo_cal.append(Row(date=date, cal_year=row.cal_year, cal_month=row.cal_month))\n",
        "                date = date + timedelta(days=1)\n",
        "\n",
        "        df_promo_cal = sqlContext.createDataFrame(ad_promo_cal)\n",
        "\n",
        "        df_promo_cal.createOrReplaceTempView(\"df_promo_cal\")\n",
        "\n",
        "        df = sqlContext.sql(\"select A.sku_rk, A.cssku, A.qty_sold, A.sales_price, A.sales_cost, B.cal_year, B.cal_month from \" + daily_sales_store_sku + \" A left join df_promo_cal B on A.csdate=B.date\")\n",
        "\n",
        "        if dates != []:\n",
        "\n",
        "            print(\"Filtering on months based on dates\")\n",
        "            df.createOrReplaceTempView(\"df\")\n",
        "\n",
        "            as_of_date = []\n",
        "            for each_date in dates:\n",
        "                as_of_date.append(\"'\" + str(each_date) + \"'\")\n",
        "\n",
        "            csdates_list = ','.join(as_of_date)\n",
        "\n",
        "            date_filter = \" date in (\" + csdates_list + \")\"\n",
        "\n",
        "            print(date_filter)\n",
        "\n",
        "            df_filter_year_month_cal = sqlContext.sql(\"select distinct cal_year as year, cal_month as month from df_promo_cal where \" + date_filter)\n",
        "\n",
        "            df_filter_year_month_cal.createOrReplaceTempView(\"df_filter_year_month_cal\")\n",
        "\n",
        "            df = sqlContext.sql(\"select A.cssku, A.qty_sold, A.sales_price, A.sales_cost, A.cal_year, A.cal_month from df A join df_filter_year_month_cal B on A.cal_year=B.year and A.cal_month=B.month\")\n",
        "            df.createOrReplaceTempView(\"df\")\n",
        "            df_filtered = sqlContext.sql(\"select distinct cal_year, cal_month from df\")\n",
        "            df_filtered.show()\n",
        "\n",
        "            print(\"Computing ETL...\")\n",
        "            #df.createOrReplaceTempView(\"df\")\n",
        "\n",
        "            #df_filtered_2 = sqlContext.sql(\"select distinct cal_year, cal_month from df\")\n",
        "            #df_filtered_2.show()\n",
        "            df_agg_ad_promo_monthly_sales = df.groupBy(\"sku_rk\",\"cssku\",\"cal_year\",\"cal_month\").agg(sum(col(\"qty_sold\")).alias(\"qty_sold\")\n",
        "                                                                                         , sum(col(\"sales_price\")).alias(\"gross_price\")\n",
        "                                                                                         , sum(col(\"sales_cost\")).alias(\"sales_cost\"))\n",
        "\n",
        "            df_agg_ad_promo_monthly_sales.createOrReplaceTempView(\"df_final_ad_promo_monthly_sales\")\n",
        "\n",
        "            df_sku_base_product_group = sqlContext.sql(\"select sku_number,merchandise_group_desc from \" +  sku_prodgrp_table_name)\n",
        "            df_sku_base_product_group.createOrReplaceTempView(\"df_sku_base_product_group\")\n",
        "\n",
        "            df_sku_base_product_join = sqlContext.sql(\"select A.sku_rk, A.cssku, A.qty_sold, A.gross_price, A.sales_cost, A.cal_year, A.cal_month, B.merchandise_group_desc \\\n",
        "                                                           from df_final_ad_promo_monthly_sales A left join df_sku_base_product_group B \\\n",
        "                                                            on A.cssku = B.sku_number\")\n",
        "\n",
        "            df_sku_base_product_join.createOrReplaceTempView(\"df_final_ad_promo_sales\")\n",
        "\n",
        "            df_ad_promo_monthly_sales = sqlContext.sql(\"select cast(sku_rk as int), \\\n",
        "                                                                    cast(cssku as bigint) skunum, \\\n",
        "                                                                    cast(qty_sold as decimal(31,3)),\\\n",
        "                                                                    cast(gross_sales as decimal(34,2)) sales_price, \\\n",
        "                                                                    cast(sales_cost as decimal(34,4)),\\\n",
        "                                                                    cast (cal_year as smallint) year, \\\n",
        "                                                                    cast (cal_month as tinyint) month,\\\n",
        "                                                                    cast (merchandise_group_desc as varchar(50))  \\\n",
        "                                                                    from df_final_ad_promo_sales \")\n",
        "\n",
        "        return df_ad_promo_monthly_sales"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": [
        "%pyspark\n",
        "\n",
        "def agg_sales_by_store_sku_transaction(df):\n",
        "        \"\"\" Transformation to aggregate sales by store, sku, transaction\n",
        "\n",
        "        Args:\n",
        "            df (DataFrame) : DataFrame (sales transaction level details) to transform.\n",
        "\n",
        "        Returns:\n",
        "            df (DataFrame) : Transformed DataFrame\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        return df.groupby(\"invoice_year\"\n",
        "                          , \"invoice_period\"\n",
        "                          , \"csdate\"\n",
        "                          , \"csstor\"\n",
        "                          , \"cstran\"\n",
        "                          , \"csreg\"\n",
        "                          , \"csroll\"\n",
        "                          , \"cssku\"\n",
        "                          ).agg(count(\"csacct\").alias(\"sources_total\")\n",
        "                                , sum(when(df.csacct != ' ', 1).otherwise(0)).alias(\"sources_outstore\")\n",
        "                                , sum(when(df.csacct == ' ', 1).otherwise(0)).alias(\"sources_instore\")\n",
        "                                , sum(\"csqty\").alias(\"qty_total\")\n",
        "                                , sum(when(df.csacct != ' ', col(\"csqty\")).otherwise(0)).alias(\"qty_outstore\")\n",
        "                                , sum(when(df.csacct == ' ', col(\"csqty\")).otherwise(0)).alias(\"qty_instore\")\n",
        "                                , sum(when(df.csdtyp == '11', -1 * col(\"csqty\")).otherwise(0)).alias(\"qty_returns\")\n",
        "                                , sum(\"csexpr\").alias(\"amt_total\")\n",
        "                                , avg(\"cscost\").alias(\"cost_unit\")\n",
        "                                                                )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": [
        "%pyspark\n",
        "\n",
        "def agg_sales_by_store_sku(df):\n",
        "        \"\"\" Transformation to aggregate sales by store, sku\n",
        "\n",
        "        Args:\n",
        "            df (DataFrame) : DataFrame (sales store,sku level details) to transform.\n",
        "\n",
        "        Returns:\n",
        "            df (DataFrame) : Transformed DataFrame\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        return df.groupby(\"invoice_year\"\n",
        "                          , \"invoice_period\"\n",
        "                          , \"csdate\"\n",
        "                          , \"csstor\"\n",
        "                          , \"cssku\"\n",
        "                          ).agg(count(\"csacct\").alias(\"sources_total\")\n",
        "                                , sum(when(df.csacct != ' ', 1).otherwise(0)).alias(\"sources_outstore\")\n",
        "                                , sum(when(df.csacct == ' ', 1).otherwise(0)).alias(\"sources_instore\")\n",
        "                                , sum(\"csqty\").alias(\"qty_total\")\n",
        "                                , sum(when(df.csacct != ' ', col(\"csqty\")).otherwise(0)).alias(\"qty_outstore\")\n",
        "                                , sum(when(df.csacct == ' ', col(\"csqty\")).otherwise(0)).alias(\"qty_instore\")\n",
        "                                , sum(when(df.csdtyp == '11', -1 * col(\"csqty\")).otherwise(0)).alias(\"qty_returns\")\n",
        "                                , sum(\"csexpr\").alias(\"amt_total\")\n",
        "                                , avg(\"cscost\").alias(\"cost_unit\")\n",
        "                                )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": [
        "%pyspark\n",
        "\n",
        "def agg_sales_by_store_sku_transaction_rolling_window_cy(agg_with_sku_data_part_type):\n",
        "        \"\"\" Transformation to compute cy, py, ppy aggregates\n",
        "\n",
        "        Args:\n",
        "            df (DataFrame) : DataFrame (sales transaction level details) to transform.\n",
        "\n",
        "        Returns:\n",
        "            df (DataFrame) : Transformed DataFrame\n",
        "\n",
        "        \"\"\"\n",
        "        agg_with_sku_data_part_type.registerTempTable(\"dfx\")\n",
        "\n",
        "        agg_cy = sqlContext.sql(\"select\\\n",
        "                          csstor \\\n",
        "                        , cstran \\\n",
        "                        , csreg \\\n",
        "                        , csroll \\\n",
        "                        , cssku , sources_total\\\n",
        "                        , sources_outstore \\\n",
        "                        , sources_instore \\\n",
        "                        , qty_total \\\n",
        "                        , qty_outstore \\\n",
        "                        , qty_instore \\\n",
        "                        , qty_returns \\\n",
        "                        ,case when csdate between date_add(add_months(csdate,-12),1) and csdate then sum(qty_total) \\\n",
        "                         over w else 0 end as cy_qty_total \\\n",
        "                        ,case when csdate between date_add(add_months(csdate,-12),1) and csdate then sum(qty_outstore)\\\n",
        "                         over w else 0 end as cy_qty_outstore \\\n",
        "                        ,case when csdate between date_add(add_months(csdate,-12),1) and csdate then sum(qty_instore) \\\n",
        "                         over w else 0 end as cy_qty_instore \\\n",
        "        ,case when csdate between date_add(add_months(csdate,-24),1) and date_add(add_months(csdate,-12),1) \\\n",
        "        then sum(qty_total) over w else 0 end as py_qty_total \\\n",
        "        ,case when csdate between date_add(add_months(csdate,-24),1) and date_add(add_months(csdate,-12),1) \\\n",
        "        then sum(qty_outstore) over w else 0 end as py_qty_outstore \\\n",
        "        ,case when csdate between date_add(add_months(csdate,-24),1) and date_add(add_months(csdate,-12),1) \\\n",
        "        then sum(qty_instore) over w else 0 end as py_qty_instore \\\n",
        "        ,case when csdate between date_add(add_months(csdate,-36),1) and date_add(add_months(csdate,-24),1) \\\n",
        "        then sum(qty_total) over w else 0 end as ppy_qty_total \\\n",
        "        ,case when csdate between date_add(add_months(csdate,-36),1) and date_add(add_months(csdate,-24),1) \\\n",
        "        then sum(qty_outstore) over w else 0 end as ppy_qty_outstore \\\n",
        "        ,case when csdate between date_add(add_months(csdate,-36),1) and date_add(add_months(csdate,-24),1) \\\n",
        "         then sum(qty_instore) over w else 0 end as ppy_qty_instore \\\n",
        "                        ,amt_total \\\n",
        "                        ,cost_unit \\\n",
        "                        , store_zipcode \\\n",
        "                        , store_state \\\n",
        "                        , store_dc \\\n",
        "                        , store_lat \\\n",
        "                        , store_long \\\n",
        "                        , store_open_flag \\\n",
        "                        , store_open_date \\\n",
        "                        , store_close_date \\\n",
        "                        , store_superhub \\\n",
        "                        , merchandise_division_desc \\\n",
        "                        , merchandise_group_desc \\\n",
        "                        , merchandise_department_desc \\\n",
        "                        , merchandise_class_desc \\\n",
        "                        , merchandise_subclass_desc \\\n",
        "                        , mpog_id \\\n",
        "                        , mpog_description \\\n",
        "                        , mpog_flag \\\n",
        "                        , discontinued_flg \\\n",
        "                        , stocking_location \\\n",
        "                        , part_type \\\n",
        "                        , invoice_year \\\n",
        "                        , invoice_period \\\n",
        "                        , csdate \\\n",
        "                from dfx \\\n",
        "                    WINDOW w as (partition by invoice_year,invoice_period, csstor, cstran, csreg, csroll\\\n",
        "                         , cssku)\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        return agg_cy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": [
        "%pyspark\n",
        "\n",
        "def agg_sales_by_store_sku_rolling_window_cy(agg_with_sku_part_type):\n",
        "        \"\"\" Transformation to compute cy, py, ppy aggregates\n",
        "\n",
        "        Args:\n",
        "            df (DataFrame) : DataFrame (sales store,sku level details) to transform.\n",
        "\n",
        "        Returns:\n",
        "            df (DataFrame) : Transformed DataFrame\n",
        "\n",
        "        \"\"\"\n",
        "        agg_with_sku_part_type.registerTempTable(\"dfx\")\n",
        "\n",
        "        agg_store_sku_df = sqlContext.sql(\"select csstor \\\n",
        "                        , cssku \\\n",
        "                        , sources_total\\\n",
        "                        , sources_outstore \\\n",
        "                        , sources_instore \\\n",
        "                        , qty_total \\\n",
        "                        , qty_outstore \\\n",
        "                        , qty_instore \\\n",
        "                        , qty_returns \\\n",
        "                        ,case when csdate between date_add(add_months(csdate,-12),1) and csdate then sum(qty_total) \\\n",
        "                         over w else 0 end as cy_qty_total \\\n",
        "                        ,case when csdate between date_add(add_months(csdate,-12),1) and csdate then sum(qty_outstore)\\\n",
        "                         over w else 0 end as cy_qty_outstore \\\n",
        "                        ,case when csdate between date_add(add_months(csdate,-12),1) and csdate then sum(qty_instore) \\\n",
        "                         over w else 0 end as cy_qty_instore \\\n",
        "                        ,case when csdate between date_add(add_months(csdate,-24),1) and date_add(add_months(csdate,-12),1) then sum(qty_total) \\\n",
        "                         over w else 0 end as py_qty_total \\\n",
        "                        ,case when csdate between date_add(add_months(csdate,-24),1) and date_add(add_months(csdate,-12),1) then sum(qty_outstore)\\\n",
        "                         over w else 0 end as py_qty_outstore \\\n",
        "                        ,case when csdate between date_add(add_months(csdate,-24),1) and date_add(add_months(csdate,-12),1) then sum(qty_instore) \\\n",
        "                         over w else 0 end as py_qty_instore \\\n",
        "                        ,case when csdate between date_add(add_months(csdate,-36),1) and date_add(add_months(csdate,-24),1) then sum(qty_total) \\\n",
        "                         over w else 0 end as ppy_qty_total \\\n",
        "                        ,case when csdate between date_add(add_months(csdate,-36),1) and date_add(add_months(csdate,-24),1) then sum(qty_outstore)\\\n",
        "                         over w else 0 end as ppy_qty_outstore \\\n",
        "                        ,case when csdate between date_add(add_months(csdate,-36),1) and date_add(add_months(csdate,-24),1) then sum(qty_instore) \\\n",
        "                         over w else 0 end as ppy_qty_instore \\\n",
        "                        , amt_total\\\n",
        "                        , cost_unit \\\n",
        "                        , '' as cy_gross_sales\\\n",
        "                        , '' as py_gross_sales\\\n",
        "                        , '' as ppy_gross_sales\\\n",
        "                        , (case when csdate between date_add(add_months(csdate,-12),1) and csdate then sum(qty_total) \\\n",
        "                         over w else 0 end)*cost_unit as cy_sales_cost \\\n",
        "                        , (case when csdate between date_add(add_months(csdate,-24),1) and date_add(add_months(csdate,-12),1) then sum(qty_total) \\\n",
        "                         over w else 0 end)*cost_unit as py_sales_cost \\\n",
        "                        ,(case when csdate between date_add(add_months(csdate,-36),1) and date_add(add_months(csdate,-24),1) then sum(qty_total) \\\n",
        "                        over w else 0 end)*cost_unit as ppy_sales_cost \\\n",
        "                        ,'' as cq_unit_sales \\\n",
        "                        , '' as cq_gross_sales \\\n",
        "                        , '' as cq_sales_cost \\\n",
        "                        , '' as ppy_unit_sales \\\n",
        "                        , store_zipcode\\\n",
        "                        , store_state \\\n",
        "                        , store_dc\\\n",
        "                        , store_open_date \\\n",
        "                        , store_close_date\\\n",
        "                        , store_open_flag\\\n",
        "                        , store_lat\\\n",
        "                        , store_long \\\n",
        "                        , store_superhub \\\n",
        "                        , merchandise_division_desc\\\n",
        "                        , merchandise_group_desc \\\n",
        "                        , merchandise_department_desc\\\n",
        "                        , merchandise_class_desc \\\n",
        "                        , merchandise_subclass_desc\\\n",
        "                        , mpog_id \\\n",
        "                        , mpog_description\\\n",
        "                        , mpog_flag\\\n",
        "                        , discontinued_flg\\\n",
        "                        , stocking_location \\\n",
        "                        , part_type \\\n",
        "                        , invoice_year \\\n",
        "                        , invoice_period\\\n",
        "                        , csdate\\\n",
        "                         from dfx \\\n",
        "                         WINDOW w as (partition by invoice_year,invoice_period, invoice_year, csstor, cssku)\")\n",
        "\n",
        "        return agg_store_sku_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": [
        "%pyspark\n",
        "\n",
        "def fps_start_end_info(cdate, nPeriods):\n",
        "    current_period_info = fp_info(cdate)\n",
        "    # If cdate is the last day of the period, include that and go back nPeriods -1\n",
        "    # If not, go back nPeriods.\n",
        "    start_period_sequence_id = current_period_info.sequence_id - nPeriods + 1\n",
        "    end_period_sequence_id = current_period_info.sequence_id;\n",
        "    end_period_info = None\n",
        "    if (current_period_info.end_date != cdate):\n",
        "        start_period_sequence_id -= 1\n",
        "        end_period_sequence_id -= 1\n",
        "        #end_period_info = current_period_info\n",
        "    else:\n",
        "        #end_period_sequence_id -= 1\n",
        "        pass\n",
        "    start_period_info = get_pc_df().filter(col('sequence_id') == start_period_sequence_id).first()\n",
        "\n",
        "    if not end_period_info:\n",
        "        end_period_info = get_pc_df().filter(col('sequence_id') == end_period_sequence_id).first()\n",
        "\n",
        "    x=start_period_info.start_date\n",
        "    #print 'hello'\n",
        "    #print x\n",
        "\n",
        "    #y = Row(start_period_info= start_period_info, end_period_info= end_period_info)\n",
        "    #print y\n",
        "    return  Row(start_period_info= start_period_info, end_period_info= end_period_info)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": [
        "%pyspark\n",
        "\n",
        "def fp_info(cdate):\n",
        "    # The return value will be a Row and will have the following fields:\n",
        "    # sequence_id\n",
        "    # cal_period\n",
        "    # cal_year\n",
        "    # end_date # datetime.datetime\n",
        "    # start_date # datetime.datetime\n",
        "    # days_in_period\n",
        "    return  get_pc_df().filter((cdate >= col('start_date')) & (cdate <= col('end_date'))).first()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": [
        "%pyspark\n",
        "\n",
        "def fps_start_end_info(cdate, nPeriods):\n",
        "    current_period_info = fp_info(cdate)\n",
        "    # If cdate is the last day of the period, include that and go back nPeriods -1\n",
        "    # If not, go back nPeriods.\n",
        "    start_period_sequence_id = current_period_info.sequence_id - nPeriods + 1\n",
        "    end_period_sequence_id = current_period_info.sequence_id;\n",
        "    end_period_info = None\n",
        "    if (current_period_info.end_date != cdate):\n",
        "        start_period_sequence_id -= 1\n",
        "        end_period_sequence_id -= 1\n",
        "        #end_period_info = current_period_info\n",
        "    else:\n",
        "        #end_period_sequence_id -= 1\n",
        "        pass\n",
        "    start_period_info = get_pc_df().filter(col('sequence_id') == start_period_sequence_id).first()\n",
        "\n",
        "    if not end_period_info:\n",
        "        end_period_info = get_pc_df().filter(col('sequence_id') == end_period_sequence_id).first()\n",
        "\n",
        "    x=start_period_info.start_date\n",
        "    #print 'hello'\n",
        "    #print x\n",
        "\n",
        "    #y = Row(start_period_info= start_period_info, end_period_info= end_period_info)\n",
        "    #print y\n",
        "    return  Row(start_period_info= start_period_info, end_period_info= end_period_info)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": [
        "%pyspark\n",
        "\n",
        "def agg_sales_by_store_sku_rolling_sales(df, as_of_date):\n",
        "        \"\"\" Transformation to compute cy, py, ppy aggregates\n",
        "\n",
        "        Args:\n",
        "            df (DataFrame) : DataFrame (sales store,sku level details) to transform.\n",
        "\n",
        "        Returns:\n",
        "            df (DataFrame) : Transformed DataFrame\n",
        "\n",
        "        \"\"\"\n",
        "        df.createOrReplaceTempView(\"df\")\n",
        "        # cy calendar year date range\n",
        "        max_date = sqlContext.sql('select max(csdate) as fy from df')\n",
        "        cy_end_date = max_date.first()[0]\n",
        "        cy_start_date = get_previous_year_start_date(max_date.first()[0])\n",
        "        print(\"DEBUG cy_start_date \")\n",
        "        print(cy_start_date)\n",
        "        print(\"DEBUG cy_end_date \")\n",
        "        print(cy_end_date)\n",
        "\n",
        "        # py calendear year date range\n",
        "        py_end_date = cy_start_date+ datetime.timedelta(days=-1)\n",
        "        py_start_date = get_previous_year_start_date(cy_start_date+ datetime.timedelta(days=-1))\n",
        "        print(\"DEBUG py_start_date \")\n",
        "        print(py_start_date)\n",
        "        print(\"DEBUG py_end_date \")\n",
        "        print(py_end_date)\n",
        "\n",
        "        # ppy calendear year date range\n",
        "        ppy_end_date = py_start_date+ datetime.timedelta(days=-1)\n",
        "        ppy_start_date = get_previous_year_start_date(py_start_date+ datetime.timedelta(days=-1))\n",
        "        print(\"DEBUG ppy_start_date \")\n",
        "        print(ppy_start_date)\n",
        "        print(\"DEBUG ppy_end_date \")\n",
        "        print(ppy_end_date)\n",
        "        \n",
        "        # 3py calendear year date range\n",
        "        pppy_end_date = ppy_start_date+ datetime.timedelta(days=-1)\n",
        "        pppy_start_date = get_previous_year_start_date(ppy_start_date+ datetime.timedelta(days=-1))\n",
        "        print(\"DEBUG 3py_start_date \")\n",
        "        print(pppy_start_date)\n",
        "        print(\"DEBUG 3py_end_date \")\n",
        "        print(pppy_end_date)\n",
        "\n",
        "        # cq 3 period date range\n",
        "        cq_fp_period_info = fps_start_end_info(as_of_date, 3)\n",
        "        cq_fp_start_date = cq_fp_period_info.start_period_info.start_date\n",
        "        cq_fp_end_date = cq_fp_period_info.end_period_info.end_date\n",
        "        print(\"DEBUG cq_fp_start_date \")\n",
        "        print(cq_fp_start_date)\n",
        "        print(\"DEBUG cq_fp_end_date \")\n",
        "        print(cq_fp_end_date)\n",
        "\n",
        "        # cy 13 period date range\n",
        "        cy_fp_period_info = fps_start_end_info(as_of_date, 13)\n",
        "        cy_fp_start_date = cy_fp_period_info.start_period_info.start_date\n",
        "        cy_fp_end_date = cy_fp_period_info.end_period_info.end_date\n",
        "        print(\"DEBUG cy_fp_start_date \")\n",
        "        print(cy_fp_start_date)\n",
        "        print(\"DEBUG cy_fp_end_date \")\n",
        "        print(cy_fp_end_date)\n",
        "\n",
        "        # py 13 period date range\n",
        "        py_fp_period_info = fps_start_end_info(as_of_date, 26)\n",
        "        py_fp_start_date = py_fp_period_info.start_period_info.start_date\n",
        "        py_fp_end_date = cy_fp_start_date - datetime.timedelta(days=1)\n",
        "        print(\"DEBUG py_fp_start_date \")\n",
        "        print(py_fp_start_date)\n",
        "        print(\"DEBUG py_fp_end_date \")\n",
        "        print(py_fp_end_date)\n",
        "\n",
        "        # ppy 13 period date range\n",
        "        ppy_fp_period_info = fps_start_end_info(as_of_date, 39)\n",
        "        ppy_fp_start_date = ppy_fp_period_info.start_period_info.start_date\n",
        "        ppy_fp_end_date = py_fp_start_date - datetime.timedelta(days=1)\n",
        "        print(\"DEBUG ppy_fp_start_date \")\n",
        "        print(ppy_fp_start_date)\n",
        "        print(\"DEBUG ppy_fp_end_date \")\n",
        "        print(ppy_fp_end_date)\n",
        "        \n",
        "        # 3py 13 period date range\n",
        "        pppy_fp_period_info = fps_start_end_info(as_of_date, 52)\n",
        "        pppy_fp_start_date = pppy_fp_period_info.start_period_info.start_date\n",
        "        pppy_fp_end_date = ppy_fp_start_date - datetime.timedelta(days=1)\n",
        "        print(\"DEBUG 3py_fp_start_date \")\n",
        "        print(pppy_fp_start_date)\n",
        "        print(\"DEBUG 3py_fp_end_date \")\n",
        "        print(pppy_fp_end_date)\n",
        "\n",
        "        print(\"DEBUG df.printSchema() \")\n",
        "        df.printSchema()\n",
        "\n",
        "        x =  df.groupby( \"csstor\"\n",
        "                          , \"cssku\"\n",
        "                          ).agg(count(\"csacct\").alias(\"sources_total\")\n",
        "                                , sum(when(df.csacct != ' ', 1).otherwise(0)).alias(\"sources_outstore\")\n",
        "                                , sum(when(((df.csacct == ' ') | (df.csacct.isNull())), 1).otherwise(0)).alias(\"sources_instore\")\n",
        "\n",
        "                                # Year based qty_total\n",
        "                                , sum(when(((df.csdate >= cy_start_date) & (df.csdate <= cy_end_date)), col(\"csqty\")).\n",
        "                                      otherwise(0)).alias(\"cyfy_qty_total\")\n",
        "\n",
        "                                # CY (Financial period based current year ==> -13 periods)\n",
        "                                , sum(when(((df.csdate >= cy_fp_start_date) & (df.csdate <= cy_fp_end_date)), col(\"csqty\")).\n",
        "                                      otherwise(0)).alias(\"p_cy_unit_sales\")\n",
        "                                , sum(when(((df.csacct != ' ') & (df.csdate >= cy_fp_start_date) & (df.csdate <= cy_fp_end_date)), col(\"csqty\")).\n",
        "                                      otherwise(0)).alias(\"p_cy_unit_sales_transfer\")\n",
        "                                , sum(when((((df.csacct == ' ') | (df.csacct.isNull())) & (df.csdate >= cy_fp_start_date) & (df.csdate <= cy_fp_end_date)), col(\"csqty\")).\n",
        "                                      otherwise(0)).alias(\"p_cy_unit_sales_on_hand\")\n",
        "                                , sum(when(((df.csdate >= cy_fp_start_date) & (df.csdate <= cy_fp_end_date)), col(\"csexpr\")).\n",
        "                                      otherwise(0)).alias(\"p_cy_gross_sales\")\n",
        "                                , sum(when(((df.csdate >= cy_fp_start_date) & (df.csdate <= cy_fp_end_date)), col(\"csqty\") * col(\"cscost\")).\n",
        "                                      otherwise(0)).alias(\"p_cy_sales_cost\")\n",
        "\n",
        "                                # PY (Financial period based current year ==> -26 to -14 periods)\n",
        "                                , sum(when(((df.csdate >= py_fp_start_date) & (df.csdate <= py_fp_end_date)), col(\"csqty\")).\n",
        "                                      otherwise(0)).alias(\"p_py_unit_sales\")\n",
        "                                , sum(when(((df.csacct != ' ') & (df.csdate >= py_fp_start_date) & (df.csdate <= py_fp_end_date)), col(\"csqty\")).\n",
        "                                      otherwise(0)).alias(\"p_py_unit_sales_transfer\")\n",
        "                                , sum(when((((df.csacct == ' ') | (df.csacct.isNull())) & (df.csdate >= py_fp_start_date) & (df.csdate <= py_fp_end_date)), col(\"csqty\")).\n",
        "                                      otherwise(0)).alias(\"p_py_unit_sales_on_hand\")\n",
        "                                , sum(when(((df.csdate >= py_fp_start_date) & (df.csdate <= py_fp_end_date)), col(\"csexpr\")).\n",
        "                                      otherwise(0)).alias(\"p_py_gross_sales\")\n",
        "                                , sum(when(((df.csdate >= py_fp_start_date) & (df.csdate <= py_fp_end_date)), col(\"csqty\") * col(\"cscost\")).\n",
        "                                      otherwise(0)).alias(\"p_py_sales_cost\")\n",
        "\n",
        "                                # PPY (Financial period based current year ==> -39 to -25 periods)\n",
        "                                , sum(when(((df.csdate >= ppy_fp_start_date) & (df.csdate <= ppy_fp_end_date)), col(\"csqty\")).\n",
        "                                      otherwise(0)).alias(\"p_ppy_unit_sales\")\n",
        "                                , sum(when(((df.csacct != ' ') & (df.csdate >= ppy_fp_start_date)), col(\"csqty\")).\n",
        "                                      otherwise(0)).alias(\"p_ppy_unit_sales_transfer\")\n",
        "                                , sum(when((((df.csacct == ' ') | (df.csacct.isNull())) & (df.csdate >= ppy_fp_start_date) & (df.csdate <= ppy_fp_end_date)), col(\"csqty\")).\n",
        "                                      otherwise(0)).alias(\"p_ppy_unit_sales_on_hand\")\n",
        "                                , sum(when(((df.csdate >= ppy_fp_start_date) & (df.csdate <= ppy_fp_end_date)), col(\"csexpr\")).\n",
        "                                      otherwise(0)).alias(\"p_ppy_gross_sales\")\n",
        "                                , sum(when(((df.csdate >= ppy_fp_start_date) & (df.csdate <= ppy_fp_end_date)), col(\"csqty\") * col(\"cscost\")).\n",
        "                                      otherwise(0)).alias(\"p_ppy_sales_cost\")\n",
        "                                      \n",
        "                                # 3PY (Financial period based current year ==> -52 to -39 periods)\n",
        "                                , sum(when(((df.csdate >= pppy_fp_start_date) & (df.csdate <= pppy_fp_end_date)), col(\"csqty\")).\n",
        "                                      otherwise(0)).alias(\"p_pppy_unit_sales\")\n",
        "                                , sum(when(((df.csacct != ' ') & (df.csdate >= pppy_fp_start_date)), col(\"csqty\")).\n",
        "                                      otherwise(0)).alias(\"p_pppy_unit_sales_transfer\")\n",
        "                                , sum(when((((df.csacct == ' ') | (df.csacct.isNull())) & (df.csdate >= pppy_fp_start_date) & (df.csdate <= pppy_fp_end_date)), col(\"csqty\")).\n",
        "                                      otherwise(0)).alias(\"p_pppy_unit_sales_on_hand\")\n",
        "                                , sum(when(((df.csdate >= pppy_fp_start_date) & (df.csdate <= pppy_fp_end_date)), col(\"csexpr\")).\n",
        "                                      otherwise(0)).alias(\"p_pppy_gross_sales\")\n",
        "                                , sum(when(((df.csdate >= pppy_fp_start_date) & (df.csdate <= pppy_fp_end_date)), col(\"csqty\") * col(\"cscost\")).\n",
        "                                      otherwise(0)).alias(\"p_pppy_sales_cost\")\n",
        "\n",
        "                                # CQ (Financial period based current quarter)\n",
        "                                , sum(when(((df.csdate >= cq_fp_start_date) & (df.csdate <= cq_fp_end_date)), col(\"csqty\")).\n",
        "                                      otherwise(0)).alias(\"cq_unit_sales\")\n",
        "                                , sum(when(((df.csdate >= cq_fp_start_date) & (df.csdate <= cq_fp_end_date)), col(\"csexpr\")).\n",
        "                                      otherwise(0)).alias(\"cq_gross_sales\")\n",
        "                                , sum(when(((df.csdate >= cq_fp_start_date) & (df.csdate <= cq_fp_end_date)), col(\"csqty\") * col(\"cscost\")).\n",
        "                                      otherwise(0)).alias(\"cq_sales_cost\")\n",
        "\n",
        "                                # CY ( based on max csdate from invoice_cshdet current year ==> 1 year back)\n",
        "                                , sum(when(((df.csdate >= cy_start_date) & (df.csdate <= cy_end_date)), col(\"csqty\")).\n",
        "                                      otherwise(0)).alias(\"cy_unit_sales\")\n",
        "                                , sum(when(((df.csacct != ' ') & (df.csdate >= cy_start_date) & (df.csdate <= cy_end_date)),col(\"csqty\")).\n",
        "                                      otherwise(0)).alias(\"cy_unit_sales_transfer\")\n",
        "                                , sum(when((((df.csacct == ' ') | (df.csacct.isNull())) & (df.csdate >= cy_start_date) & (df.csdate <= cy_end_date)), col(\"csqty\")).\n",
        "                                      otherwise(0)).alias(\"cy_unit_sales_on_hand\")\n",
        "                                , sum(when(((df.csdate >= cy_start_date) & (df.csdate <= cy_end_date)), col(\"csexpr\")).\n",
        "                                      otherwise(0)).alias(\"cy_gross_sales\")\n",
        "                                , sum(when(((df.csdate >= cy_start_date) & (df.csdate <= cy_end_date)), col(\"csqty\") * col(\"cscost\")).\n",
        "                                      otherwise(0)).alias(\"cy_sales_cost\")\n",
        "\n",
        "                                # PY ( based on max csdate from invoice_cshdet current year ==> 2 years back)\n",
        "                                , sum(when(((df.csdate >= py_start_date) & (df.csdate <= py_end_date)), col(\"csqty\")).\n",
        "                                      otherwise(0)).alias(\"py_unit_sales\")\n",
        "                                , sum(when(((df.csacct != ' ') & (df.csdate >= py_start_date) & (df.csdate <= py_end_date)), col(\"csqty\")).\n",
        "                                      otherwise(0)).alias(\"py_unit_sales_transfer\")\n",
        "                                , sum(when((((df.csacct == ' ') | (df.csacct.isNull())) & ( df.csdate >= py_start_date) & (df.csdate <= py_end_date)), col(\"csqty\")).\n",
        "                                      otherwise(0)).alias(\"py_unit_sales_on_hand\")\n",
        "                                ,sum(when(((df.csdate >= py_start_date) & (df.csdate <= py_end_date)), col(\"csexpr\")).\n",
        "                                      otherwise(0)).alias(\"py_gross_sales\")\n",
        "                                , sum(when(((df.csdate >= py_start_date) & (df.csdate <= py_end_date)), col(\"csqty\") * col(\"cscost\")).\n",
        "                                      otherwise(0)).alias(\"py_sales_cost\")\n",
        "\n",
        "                                # PPY (based on max csdate from invoice_cshdet current year ==> 3 years back)\n",
        "                                , sum(when(((df.csdate >= ppy_start_date) & (df.csdate <= ppy_end_date)), col(\"csqty\")).\n",
        "                                      otherwise(0)).alias(\"ppy_unit_sales\")\n",
        "                                , sum(when(((df.csacct != ' ') & (df.csdate >= ppy_start_date) & (df.csdate <= ppy_end_date)), col(\"csqty\")).\n",
        "                                      otherwise(0)).alias(\"ppy_unit_sales_transfer\")\n",
        "                                , sum(when((((df.csacct == ' ') | (df.csacct.isNull())) & (df.csdate >= ppy_start_date) & (df.csdate <= ppy_end_date)), col(\"csqty\")).\n",
        "                                      otherwise(0)).alias(\"ppy_unit_sales_on_hand\")\n",
        "                                ,sum(when(((df.csdate >= ppy_start_date) & (df.csdate <= ppy_end_date)), col(\"csexpr\")).\n",
        "                                      otherwise(0)).alias(\"ppy_gross_sales\")\n",
        "                                , sum(when(((df.csdate >= ppy_start_date) & (df.csdate <= ppy_end_date)), col(\"csqty\") * col(\"cscost\")).\n",
        "                                      otherwise(0)).alias(\"ppy_sales_cost\")\n",
        "                                      \n",
        "                                # 3PY (based on max csdate from invoice_cshdet current year ==> 3 years back)\n",
        "                                , sum(when(((df.csdate >= pppy_start_date) & (df.csdate <= pppy_end_date)), col(\"csqty\")).\n",
        "                                      otherwise(0)).alias(\"pppy_unit_sales\")\n",
        "                                , sum(when(((df.csacct != ' ') & (df.csdate >= pppy_start_date) & (df.csdate <= pppy_end_date)), col(\"csqty\")).\n",
        "                                      otherwise(0)).alias(\"pppy_unit_sales_transfer\")\n",
        "                                , sum(when((((df.csacct == ' ') | (df.csacct.isNull())) & (df.csdate >= pppy_start_date) & (df.csdate <= pppy_end_date)), col(\"csqty\")).\n",
        "                                      otherwise(0)).alias(\"pppy_unit_sales_on_hand\")\n",
        "                                ,sum(when(((df.csdate >= pppy_start_date) & (df.csdate <= pppy_end_date)), col(\"csexpr\")).\n",
        "                                      otherwise(0)).alias(\"pppy_gross_sales\")\n",
        "                                , sum(when(((df.csdate >= pppy_start_date) & (df.csdate <= pppy_end_date)), col(\"csqty\") * col(\"cscost\")).\n",
        "                                      otherwise(0)).alias(\"pppy_sales_cost\")\n",
        "\n",
        "                                , sum(when(df.csacct != ' ', col(\"csqty\")).otherwise(0)).alias(\"qty_outstore\")\n",
        "                                , sum(when(df.csacct == ' ', col(\"csqty\")).otherwise(0)).alias(\"qty_instore\")\n",
        "                                , sum(when(df.csdtyp == '11', -1 * col(\"csqty\")).otherwise(0)).alias(\"qty_returns\")\n",
        "                                , sum(\"csexpr\").alias(\"amt_total\")\n",
        "                                , avg(\"cscost\").alias(\"cost_unit\")\n",
        "                                , lit(as_of_date).alias(\"as_of_date\")\n",
        "                                )\n",
        "\n",
        "        # x.withColumn('as_of_date', lit(as_of_date))\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": [
        "%pyspark\n",
        "\n",
        "def agg_sales_sku_rolling_sales(df, as_of_date):\n",
        "        \"\"\" Transformation to compute cy, py, ppy aggregates\n",
        "\n",
        "        Args:\n",
        "            df (DataFrame) : DataFrame (sales store,sku level details) to transform.\n",
        "\n",
        "        Returns:\n",
        "            df (DataFrame) : Transformed DataFrame\n",
        "\n",
        "        \"\"\"\n",
        "        df.registerTempTable(\"df\")\n",
        "        # cy calendar year date range\n",
        "        max_date = sqlContext.sql('select max(csdate) as fy from df')\n",
        "        cy_end_date = max_date.first()[0]\n",
        "        cy_start_date = get_previous_year_start_date(max_date.first()[0])\n",
        "        print(\"DEBUG cy_start_date \")\n",
        "        print(cy_start_date)\n",
        "        print(\"DEBUG cy_end_date \")\n",
        "        print(cy_end_date)\n",
        "\n",
        "        # py calendear year date range\n",
        "        py_end_date = cy_start_date+ datetime.timedelta(days=-1)\n",
        "        py_start_date = get_previous_year_start_date(cy_start_date+ datetime.timedelta(days=-1))\n",
        "        print(\"DEBUG py_start_date \")\n",
        "        print(py_start_date)\n",
        "        print(\"DEBUG py_end_date \")\n",
        "        print(py_end_date)\n",
        "\n",
        "        # ppy calendear year date range\n",
        "        ppy_end_date = py_start_date+ datetime.timedelta(days=-1)\n",
        "        ppy_start_date = get_previous_year_start_date(py_start_date+ datetime.timedelta(days=-1))\n",
        "        print(\"DEBUG ppy_start_date \")\n",
        "        print(ppy_start_date)\n",
        "        print(\"DEBUG ppy_end_date \")\n",
        "        print(ppy_end_date)\n",
        "        \n",
        "        # 3py calendear year date range\n",
        "        pppy_end_date = ppy_start_date+ datetime.timedelta(days=-1)\n",
        "        pppy_start_date = get_previous_year_start_date(ppy_start_date+ datetime.timedelta(days=-1))\n",
        "        print(\"DEBUG 3py_start_date \")\n",
        "        print(pppy_start_date)\n",
        "        print(\"DEBUG 3py_end_date \")\n",
        "        print(pppy_end_date)\n",
        "\n",
        "        # cq 3 period date range\n",
        "        cq_fp_period_info = fps_start_end_info(as_of_date, 3)\n",
        "        cq_fp_start_date = cq_fp_period_info.start_period_info.start_date\n",
        "        cq_fp_end_date = cq_fp_period_info.end_period_info.end_date\n",
        "        print(\"DEBUG cq_fp_start_date \")\n",
        "        print(cq_fp_start_date)\n",
        "        print(\"DEBUG cq_fp_end_date \")\n",
        "        print(cq_fp_end_date)\n",
        "\n",
        "        # cy 13 period date range\n",
        "        cy_fp_period_info = fps_start_end_info(as_of_date, 13)\n",
        "        cy_fp_start_date = cy_fp_period_info.start_period_info.start_date\n",
        "        cy_fp_end_date = cy_fp_period_info.end_period_info.end_date\n",
        "        print(\"DEBUG cy_fp_start_date \")\n",
        "        print(cy_fp_start_date)\n",
        "        print(\"DEBUG cy_fp_end_date \")\n",
        "        print(cy_fp_end_date)\n",
        "\n",
        "        # py 13 period date range\n",
        "        py_fp_period_info = fps_start_end_info(as_of_date, 26)\n",
        "        py_fp_start_date = py_fp_period_info.start_period_info.start_date\n",
        "        py_fp_end_date = cy_fp_start_date - datetime.timedelta(days=1)\n",
        "        print(\"DEBUG py_fp_start_date \")\n",
        "        print(py_fp_start_date)\n",
        "        print(\"DEBUG py_fp_end_date \")\n",
        "        print(py_fp_end_date)\n",
        "\n",
        "        # ppy 13 period date range\n",
        "        ppy_fp_period_info = fps_start_end_info(as_of_date, 39)\n",
        "        ppy_fp_start_date = ppy_fp_period_info.start_period_info.start_date\n",
        "        ppy_fp_end_date = py_fp_start_date - datetime.timedelta(days=1)\n",
        "        print(\"DEBUG ppy_fp_start_date \")\n",
        "        print(ppy_fp_start_date)\n",
        "        print(\"DEBUG ppy_fp_end_date \")\n",
        "        print(ppy_fp_end_date)\n",
        "        \n",
        "        # 3py 13 period date range\n",
        "        pppy_fp_period_info = fps_start_end_info(as_of_date, 52)\n",
        "        pppy_fp_start_date = pppy_fp_period_info.start_period_info.start_date\n",
        "        pppy_fp_end_date = ppy_fp_start_date - datetime.timedelta(days=1)\n",
        "        print(\"DEBUG 3py_fp_start_date \")\n",
        "        print(pppy_fp_start_date)\n",
        "        print(\"DEBUG 3py_fp_end_date \")\n",
        "        print(pppy_fp_end_date)\n",
        "\n",
        "        print(\"DEBUG df.printSchema() \")\n",
        "        df.printSchema()\n",
        "\n",
        "        y =  df.groupby( \"cssku\"\n",
        "                           ).agg(count(\"csacct\").alias(\"sources_total\")\n",
        "                                , sum(when(df.csacct != ' ', 1).otherwise(0)).alias(\"sources_outstore\")\n",
        "                                , sum(when(((df.csacct == ' ') | (df.csacct.isNull())), 1).otherwise(0)).alias(\"sources_instore\")\n",
        "\n",
        "                                # Year based qty_total\n",
        "                                , sum(when(((df.csdate >= cy_start_date) & (df.csdate <= cy_end_date)), col(\"csqty\")).\n",
        "                                      otherwise(0)).alias(\"cyfy_qty_total\")\n",
        "\n",
        "                                # CY (Financial period based current year ==> -13 periods)\n",
        "                                , sum(when(((df.csdate >= cy_fp_start_date) & (df.csdate <= cy_fp_end_date)), col(\"csqty\")).\n",
        "                                      otherwise(0)).alias(\"p_cy_unit_sales\")\n",
        "                                , sum(when(((df.csdate >= cy_fp_start_date) & (df.csdate <= cy_fp_end_date)), col(\"csexpr\")).\n",
        "                                      otherwise(0)).alias(\"p_cy_gross_sales\")\n",
        "                                , sum(when(((df.csdate >= cy_fp_start_date) & (df.csdate <= cy_fp_end_date)), col(\"csqty\") * col(\"cscost\")).\n",
        "                                      otherwise(0)).alias(\"p_cy_sales_cost\")\n",
        "\n",
        "                                # PY (Financial period based current year ==> -26 to -14 periods)\n",
        "                                , sum(when(((df.csdate >= py_fp_start_date) & (df.csdate <= py_fp_end_date)), col(\"csqty\")).\n",
        "                                      otherwise(0)).alias(\"p_py_unit_sales\")\n",
        "                                , sum(when(((df.csdate >= py_fp_start_date) & (df.csdate <= py_fp_end_date)), col(\"csexpr\")).\n",
        "                                      otherwise(0)).alias(\"p_py_gross_sales\")\n",
        "                                , sum(when(((df.csdate >= py_fp_start_date) & (df.csdate <= py_fp_end_date)), col(\"csqty\") * col(\"cscost\")).\n",
        "                                      otherwise(0)).alias(\"p_py_sales_cost\")\n",
        "\n",
        "                                # PPY (Financial period based current year ==> -39 to -25 periods)\n",
        "                                , sum(when(((df.csdate >= ppy_fp_start_date) & (df.csdate <= ppy_fp_end_date)), col(\"csqty\")).\n",
        "                                      otherwise(0)).alias(\"p_ppy_unit_sales\")\n",
        "                                , sum(when(((df.csdate >= ppy_fp_start_date) & (df.csdate <= ppy_fp_end_date)), col(\"csexpr\")).\n",
        "                                      otherwise(0)).alias(\"p_ppy_gross_sales\")\n",
        "                                , sum(when(((df.csdate >= ppy_fp_start_date) & (df.csdate <= ppy_fp_end_date)), col(\"csqty\") * col(\"cscost\")).\n",
        "                                      otherwise(0)).alias(\"p_ppy_sales_cost\")\n",
        "                                      \n",
        "                                # 3PY (Financial period based current year ==> -52 to -39 periods)\n",
        "                                , sum(when(((df.csdate >= pppy_fp_start_date) & (df.csdate <= pppy_fp_end_date)), col(\"csqty\")).\n",
        "                                      otherwise(0)).alias(\"p_3py_unit_sales\")\n",
        "                                , sum(when(((df.csdate >= pppy_fp_start_date) & (df.csdate <= pppy_fp_end_date)), col(\"csexpr\")).\n",
        "                                      otherwise(0)).alias(\"p_3py_gross_sales\")\n",
        "                                , sum(when(((df.csdate >= pppy_fp_start_date) & (df.csdate <= pppy_fp_end_date)), col(\"csqty\") * col(\"cscost\")).\n",
        "                                      otherwise(0)).alias(\"p_3py_sales_cost\")\n",
        "\n",
        "                                # CQ (Financial period based current quarter)\n",
        "                                , sum(when(((df.csdate >= cq_fp_start_date) & (df.csdate <= cq_fp_end_date)), col(\"csqty\")).\n",
        "                                      otherwise(0)).alias(\"cq_unit_sales\")\n",
        "                                , sum(when(((df.csdate >= cq_fp_start_date) & (df.csdate <= cq_fp_end_date)), col(\"csexpr\")).\n",
        "                                      otherwise(0)).alias(\"cq_gross_sales\")\n",
        "                                , sum(when(((df.csdate >= cq_fp_start_date) & (df.csdate <= cq_fp_end_date)), col(\"csqty\") * col(\"cscost\")).\n",
        "                                      otherwise(0)).alias(\"cq_sales_cost\")\n",
        "\n",
        "                                 # CY ( based on max csdate from invoice_cshdet current year ==> 1 year back)\n",
        "                                 , sum(when(((df.csdate >= cy_start_date) & (df.csdate <= cy_end_date)), col(\"csqty\")).\n",
        "                                       otherwise(0)).alias(\"cy_unit_sales\")\n",
        "                                 , sum(when(((df.csdate >= cy_start_date) & (df.csdate <= cy_end_date)), col(\"csexpr\")).\n",
        "                                       otherwise(0)).alias(\"cy_gross_sales\")\n",
        "                                 , sum(when(((df.csdate >= cy_start_date) & (df.csdate <= cy_end_date)), col(\"csqty\") * col(\"cscost\")).\n",
        "                                       otherwise(0)).alias(\"cy_sales_cost\")\n",
        "\n",
        "                                 # PY ( based on max csdate from invoice_cshdet current year ==> 2 years back)\n",
        "                                 , sum(when(((df.csdate >= py_start_date) & (df.csdate <= py_end_date)), col(\"csqty\")).\n",
        "                                       otherwise(0)).alias(\"py_unit_sales\")\n",
        "                                 , sum(when(((df.csdate >= py_start_date) & (df.csdate <= py_end_date)), col(\"csexpr\")).\n",
        "                                       otherwise(0)).alias(\"py_gross_sales\")\n",
        "                                 , sum(when(((df.csdate >= py_start_date) & (df.csdate <= py_end_date)), col(\"csqty\") * col(\"cscost\")).\n",
        "                                       otherwise(0)).alias(\"py_sales_cost\")\n",
        "\n",
        "                                 # PPY (based on max csdate from invoice_cshdet current year ==> 3 years back)\n",
        "                                 ,sum(when(((df.csdate >= ppy_start_date) & (df.csdate <= ppy_end_date)), col(\"csqty\")).\n",
        "                                       otherwise(0)).alias(\"ppy_unit_sales\")\n",
        "                                 ,sum(when(((df.csdate >= ppy_start_date) & (df.csdate <= ppy_end_date)), col(\"csexpr\")).\n",
        "                                       otherwise(0)).alias(\"ppy_gross_sales\")\n",
        "                                 , sum(when(((df.csdate >= ppy_start_date) & (df.csdate <= ppy_end_date)), col(\"csqty\") * col(\"cscost\")).\n",
        "                                       otherwise(0)).alias(\"ppy_sales_cost\")\n",
        "                                       \n",
        "                                # 3PY (based on max csdate from invoice_cshdet current year ==> 3 years back)\n",
        "                                 ,sum(when(((df.csdate >= pppy_start_date) & (df.csdate <= pppy_end_date)), col(\"csqty\")).\n",
        "                                       otherwise(0)).alias(\"3py_unit_sales\")\n",
        "                                 ,sum(when(((df.csdate >= pppy_start_date) & (df.csdate <= pppy_end_date)), col(\"csexpr\")).\n",
        "                                       otherwise(0)).alias(\"3py_gross_sales\")\n",
        "                                 , sum(when(((df.csdate >= pppy_start_date) & (df.csdate <= pppy_end_date)), col(\"csqty\") * col(\"cscost\")).\n",
        "                                       otherwise(0)).alias(\"3py_sales_cost\")\n",
        "\n",
        "                                , sum(when(df.csacct != ' ', col(\"csqty\")).otherwise(0)).alias(\"qty_outstore\")\n",
        "                                , sum(when(df.csacct == ' ', col(\"csqty\")).otherwise(0)).alias(\"qty_instore\")\n",
        "                                , sum(when(df.csdtyp == '11', -1 * col(\"csqty\")).otherwise(0)).alias(\"qty_returns\")\n",
        "                                , sum(\"csexpr\").alias(\"amt_total\")\n",
        "                                , avg(\"cscost\").alias(\"cost_unit\")\n",
        "                                , lit(as_of_date).alias(\"as_of_date\")\n",
        "                                )\n",
        "\n",
        "        # x.withColumn('as_of_date', lit(as_of_date))\n",
        "\n",
        "        return y\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": [
        "%pyspark\n",
        "\n",
        "def persist_agg_sales_by_sku(df, method):\n",
        "        \"\"\" Persist aggregates sales by store,sku to file.\n",
        "\n",
        "        Args:\n",
        "            rdd (DataFrame) : DataFrame (sales store,sku level details) to transform.\n",
        "\n",
        "        \"\"\"\n",
        "        df.registerTempTable(\"sales_sku_df\")\n",
        "        agg_sales_by_sku = sqlContext.sql(\" select cssku as sku_number \\\n",
        "                                                 , sources_total \\\n",
        "                                                 , sources_outstore \\\n",
        "                                                 , sources_instore \\\n",
        "                                                 , cyfy_qty_total \\\n",
        "                                                 , p_cy_unit_sales \\\n",
        "                                                 , p_cy_gross_sales \\\n",
        "                                                 , p_cy_sales_cost \\\n",
        "                                                 , p_py_unit_sales \\\n",
        "                                                 , p_py_gross_sales \\\n",
        "                                                 , p_py_sales_cost \\\n",
        "                                                 , p_ppy_unit_sales \\\n",
        "                                                 , p_ppy_gross_sales \\\n",
        "                                                 , p_ppy_sales_cost \\\n",
        "                                                 , cq_unit_sales \\\n",
        "                                                 , cq_gross_sales \\\n",
        "                                                 , cq_sales_cost \\\n",
        "                                                 , cy_unit_sales \\\n",
        "                                                 , cy_gross_sales \\\n",
        "                                                 , cy_sales_cost \\\n",
        "                                                 , py_unit_sales\\\n",
        "                                                 , py_gross_sales \\\n",
        "                                                 , py_sales_cost \\\n",
        "                                                 , ppy_unit_sales\\\n",
        "                                                 , ppy_gross_sales \\\n",
        "                                                 , ppy_sales_cost \\\n",
        "                                                 , qty_outstore \\\n",
        "                                                 , qty_instore \\\n",
        "                                                 , qty_returns \\\n",
        "                                                 , amt_total \\\n",
        "                                                 , cost_unit \\\n",
        "                                                 , as_of_date from sales_sku_df\")\n",
        "\n",
        "        return agg_sales_by_sku\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": [
        "%pyspark\n",
        "\n",
        "def persist_agg_sales_by_store_sku_rolling(df, method):\n",
        "        \"\"\" Persist aggregates sales by store,sku to file.\n",
        "\n",
        "        Args:\n",
        "            rdd (DataFrame) : DataFrame (sales store,sku level details) to transform.\n",
        "\n",
        "        \"\"\"\n",
        "        df.registerTempTable(\"sales_store_sku_df\")\n",
        "        agg_sales_by_store_sku = sqlContext.sql(\" select csstor as store_number, cssku as sku_number \\\n",
        "                                                 , sources_total \\\n",
        "                                                 , sources_outstore \\\n",
        "                                                 , sources_instore \\\n",
        "                                                 , cyfy_qty_total \\\n",
        "                                                 , p_cy_unit_sales \\\n",
        "                                                 , p_cy_unit_sales_transfer \\\n",
        "                                                 , p_cy_unit_sales_on_hand \\\n",
        "                                                 , p_cy_gross_sales \\\n",
        "                                                 , p_cy_sales_cost \\\n",
        "                                                 , p_py_unit_sales \\\n",
        "                                                 , p_py_unit_sales_transfer \\\n",
        "                                                 , p_py_unit_sales_on_hand \\\n",
        "                                                 , p_py_gross_sales \\\n",
        "                                                 , p_py_sales_cost \\\n",
        "                                                 , p_ppy_unit_sales \\\n",
        "                                                 , p_ppy_unit_sales_transfer \\\n",
        "                                                 , p_ppy_unit_sales_on_hand \\\n",
        "                                                 , p_ppy_gross_sales \\\n",
        "                                                 , p_ppy_sales_cost \\\n",
        "                                                 , cq_unit_sales \\\n",
        "                                                 , cq_gross_sales \\\n",
        "                                                 , cq_sales_cost \\\n",
        "                                                 , cy_unit_sales \\\n",
        "                                                 , cy_unit_sales_transfer \\\n",
        "                                                 , cy_unit_sales_on_hand \\\n",
        "                                                 , cy_gross_sales \\\n",
        "                                                 , cy_sales_cost \\\n",
        "                                                 , py_unit_sales\\\n",
        "                                                 , py_unit_sales_transfer \\\n",
        "                                                 , py_unit_sales_on_hand \\\n",
        "                                                 , py_gross_sales \\\n",
        "                                                 , py_sales_cost \\\n",
        "                                                 , ppy_unit_sales\\\n",
        "                                                 , ppy_unit_sales_transfer \\\n",
        "                                                 , ppy_unit_sales_on_hand \\\n",
        "                                                 , ppy_gross_sales \\\n",
        "                                                 , ppy_sales_cost \\\n",
        "                                                 , qty_outstore \\\n",
        "                                                 , qty_instore \\\n",
        "                                                 , qty_returns \\\n",
        "                                                 , amt_total \\\n",
        "                                                 , cost_unit \\\n",
        "                                                 , as_of_date from sales_store_sku_df\")\n",
        "\n",
        "\n",
        "        return agg_sales_by_store_sku"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": [
        "%pyspark\n",
        "\n",
        "def persist_store_sales_by_period(df, method):\n",
        "        \"\"\" Persist aggregates sales by store,sku to file.\n",
        "\n",
        "        Args:\n",
        "            rdd (DataFrame) : DataFrame (sales store,sku level details) to transform.\n",
        "\n",
        "        \"\"\"\n",
        "        df.registerTempTable(\"store_sales_by_period\")\n",
        "        agg_store_sales_by_period = sqlContext.sql(\" select store_number \\\n",
        "                                                 , sku_number \\\n",
        "                                                 , fiscal_year \\\n",
        "                                                 , fiscal_period \\\n",
        "                                                 , customer_type \\\n",
        "                                                 , qty_sold \\\n",
        "                                                 , gross_sales \\\n",
        "                                                 , sales_cost \\\n",
        "                                                   from store_sales_by_period\")\n",
        "\n",
        "        agg_store_sales_by_period_repartition = agg_store_sales_by_period.repartition(\"fiscal_year\", \"fiscal_period\")\n",
        "\n",
        "\n",
        "        return agg_store_sales_by_period\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": [
        "%pyspark\n",
        "\n",
        "def get_previous_year_start_date(ref_date, years=1):\n",
        "        if isinstance(ref_date, datetime.date):\n",
        "            last_year_date = datetime.date(ref_date.year - years, ref_date.month, ref_date.day)\n",
        "        else:\n",
        "            last_year_date = datetime.date(ref_date.to_datetime().year - years, ref_date.month, ref_date.day)\n",
        "        return last_year_date + datetime.timedelta(days=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": [
        "%pyspark\n",
        "\n",
        "def get_store_master_info():\n",
        "        sqlContext.sql(\"use \" + store_master_db_name)\n",
        "        return sqlContext.sql(\"select * from \" + store_master_table_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": [
        "%pyspark\n",
        "\n",
        "def get_cluster_info():\n",
        "        sqlContext.sql(\"use \" + clus_def_db_name)\n",
        "        return sqlContext.sql(\"select * from \" + clus_def_table_name)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": [
        "%pyspark\n",
        "\n",
        "def get_sku_base_product_group_info():\n",
        "        sqlContext.sql(\"use \" + sku_prodgrp_db_name)\n",
        "        return sqlContext.sql(\"select * from \" + sku_prodgrp_table_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": [
        "%pyspark\n",
        "\n",
        "def get_sku_data_info():\n",
        "        sqlContext.sql(\"use \" + sku_data_db_name)\n",
        "        return sqlContext.sql(\"select * from \" + sku_data_table_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": [
        "%pyspark\n",
        "\n",
        "def get_sku_part_info():\n",
        "        sqlContext.sql(\"use \" + sku_part_type_db_name)\n",
        "        return sqlContext.sql(\"select * from \" + sku_part_type_table_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": [
        "%pyspark\n",
        "\n",
        "def hive_metadata_repair(htable):\n",
        "        \"\"\"\n",
        "        Repair Hive table Metadata\n",
        "        \"\"\"\n",
        "\n",
        "        sqlContext.sql(\"MSCK REPAIR TABLE \" + htable)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": [
        "%pyspark\n",
        "\n",
        "def run_cmd(args_list):\n",
        "        \"\"\"\n",
        "        run linux commands\n",
        "        \"\"\"\n",
        "        # import subprocess\n",
        "        print('Running system command: {0}'.format(' '.join(args_list)))\n",
        "        proc = subprocess.Popen(args_list, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
        "        s_output, s_err = proc.communicate()\n",
        "        s_return = proc.returncode\n",
        "\n",
        "        return s_return, s_output, s_err"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": [
        "%pyspark\n",
        "\n",
        "def hdfs_path(s3path):\n",
        "        \"\"\"\n",
        "        Use replace to reset the path\n",
        "        \"\"\"\n",
        "        hdfs=s3path.replace(\"s3a://\",\"/user/hadoop/\")\n",
        "\n",
        "        return hdfs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": [
        "%pyspark\n",
        "\n",
        "def agg_data_wd_master_info(df, store_master, cluster_definition, sku_base_product_group, sku_data , sku_part_type):\n",
        "        \"\"\"add master table info to aggregated data\n",
        "        \"\"\"\n",
        "        a = df.alias(\"a\")\n",
        "        sm = store_master.alias(\"sm\")\n",
        "        agg_with_store_master = a.join(sm, a.csstor == sm.storenum, 'left_outer'). \\\n",
        "            select('a.*'\\\n",
        "                   , sm.stzip.alias(\"store_zipcode\")\\\n",
        "                   , sm.ststa.alias(\"store_state\")\\\n",
        "                   , sm.stpdq.alias(\"store_dc\")\\\n",
        "                   , sm.stopdt.alias(\"store_open_date\")\\\n",
        "                   , sm.stcldt.alias(\"store_close_date\") \\\n",
        "                   , sm.lilat.alias(\"store_lat\") \\\n",
        "                   , sm.lilong.alias(\"store_long\")\\\n",
        "                   , when (sm.stcldt.isNotNull(),'Y').otherwise('N').alias(\"store_open_flag\")\\\n",
        "                    )\n",
        "\n",
        "        cd = cluster_definition.alias(\"cd\")\n",
        "        agg_sm = agg_with_store_master.alias(\"agg_sm\")\n",
        "        agg_wd_clus_def = agg_sm.join(cd, agg_sm.csstor == cd.sfrstrnum,'left_outer' ).\\\n",
        "            select('agg_sm.*'\\\n",
        "                   ,cd.sfssshub.alias(\"store_superhub\"))\n",
        "        prod_grp = sku_base_product_group.alias(\"prod_grp\")\n",
        "        agg_cls =  agg_wd_clus_def.alias(\"agg_cls\")\n",
        "        agg_with_storeInfo_clstrInfo_prodgrp = agg_cls.join(prod_grp, agg_cls.cssku == prod_grp.sku_number ,'left_outer'). \\\n",
        "            select('agg_cls.*'\\\n",
        "                   , prod_grp.merchandise_division_desc\\\n",
        "                   , prod_grp.merchandise_group_desc\\\n",
        "                   , prod_grp.merchandise_department_desc \\\n",
        "                   , prod_grp.merchandise_class_desc \\\n",
        "                   , prod_grp.merchandise_subclass_desc)\n",
        "        agg_wd_pg = agg_with_storeInfo_clstrInfo_prodgrp.alias(\"agg_wd_pg\")\n",
        "        sd = sku_data.alias(\"sd\")\n",
        "        agg_with_sku_data_info = agg_wd_pg.join(sd, agg_wd_pg.cssku  == sd.sku_number, 'left_outer').\\\n",
        "            select('agg_wd_pg.*'\\\n",
        "                 , sd.mpog_id\\\n",
        "                 , sd.mpog_description\\\n",
        "                 , sd.mpog_flag\\\n",
        "                 , sd.discontinued_flg\\\n",
        "                 , sd.stocking_location)\n",
        "        sku_part_type = sku_part_type\n",
        "        agg_wd_sku=agg_with_sku_data_info.alias(\"agg_wd_sku\")\n",
        "        agg_with_sku_data_part_type = agg_wd_sku.join(sku_part_type, \\\n",
        "                                agg_wd_sku.cssku == sku_part_type.sku_number, 'left_outer'). \\\n",
        "            select('agg_wd_sku.*',sku_part_type.part_type )\n",
        "\n",
        "        return agg_with_sku_data_part_type\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": [
        "%pyspark\n",
        "\n",
        "invoice_cshdet = drop_sales_details_with_0_quantity(load_sales_details())\n",
        "invoice_cshdet.cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": [
        "%pyspark\n",
        "\n",
        "invoice_cshdet_date = invoice_cshdet.filter(col(\"invoice_year\")<2021)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": [
        "%pyspark\n",
        "\n",
        "# sku level rolling sales\n",
        "agg_sku_rolling = agg_sales_sku_rolling_sales(invoice_cshdet_date, date.today())\n",
        "agg_sku_rolling.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": [
        "%pyspark\n",
        "\n",
        "agg_sku_rolling.show(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": [
        "%pyspark\n",
        " \n",
        "\n",
        "# store sales by period\n",
        " \n",
        "agg_store_sales_by_period = get_store_sales_by_period(invoice_cshdet_date)\n",
        "agg_store_sales_by_period.printSchema()\n",
        "       \n",
        "persist_store_sales_by_period(agg_store_sales_by_period,method='overwrite')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": [
        "%pyspark\n",
        "\n",
        "agg_store_sales_by_period.show(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": [
        "%pyspark\n",
        "\n",
        "# store, sku level rolling sales\n",
        "agg_store_sku_rolling = agg_sales_by_store_sku_rolling_sales(invoice_cshdet_date, date.today())\n",
        "agg_store_sku_rolling.printSchema()\n",
        "      "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": [
        "%pyspark\n",
        "agg_store_sku_rolling.show(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": [
        "%pyspark\n",
        "agg_store_sku_rolling.filter(agg_store_sku_rolling.csstor == \"1001\").show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": [
        "%pyspark\n",
        "agg_store_sku_rolling.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": [
        "%pyspark\n",
        "\n",
        "# Read aap_period_calendar  (source) table name\n",
        "aap_calendar_db_name = 'dds_prod'\n",
        "aap_calendar_table_name = 'dds_prod.aap_calendar'\n",
        "\n",
        "# Read cshssdtl  (source) table name\n",
        "cshssdtl_db_name = 'dds_prod'\n",
        "cshssdtl_table_name = \"dds_prod.cshssdtl\"\n",
        "\n",
        "# Read cshsshdr  (source) table name\n",
        "cshsshdr_db_name = \"dds_prod\"\n",
        "cshsshdr_table_name = \"dds_prod.cshsshdr\"\n",
        "\n",
        "# Read agg ss_store_sku_totals table storage location (target)\n",
        "ss_store_sku_totals_db_name = \"dpdm_prod\"\n",
        "ss_store_sku_totals_table_name = \"dpdm_prod.ss_store_sku_totals\"\n",
        "\n",
        "ss_store_sku_totals_s3path = \"s3://aap-dpdm-prod/dpdm.db/ss_store_sku_totals\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": [
        "%pyspark\n",
        "\n",
        "def load_aap_calendar():\n",
        "        print(\"load app calendar\")\n",
        "        return sqlContext.sql(\"select * from \" + aap_calendar_table_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": [
        "%pyspark\n",
        "\n",
        "def cshssdtl():\n",
        "        print(\"cshssdtl\")\n",
        "        return sqlContext.sql(\"select * from \" + cshssdtl_table_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": [
        "%pyspark\n",
        "\n",
        "def cshsshdr():\n",
        "        print(\"cshsshdr\")\n",
        "        return sqlContext.sql(\"select * from \" + cshsshdr_table_name)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": [
        "%pyspark\n",
        "\n",
        "def ss_second_source_stage():\n",
        "        print(\"ss second source stage\")\n",
        "        cshssdtl_df=cshssdtl()\n",
        "        cshssdtl_df.createOrReplaceTempView('cshssdtl')\n",
        "        cshsshdr_df=cshsshdr()\n",
        "        cshsshdr_df.createOrReplaceTempView('cshsshdr')\n",
        "\n",
        "        aap_calendar_df=load_aap_calendar()\n",
        "        aap_calendar_df.createOrReplaceTempView('aap_calendar')\n",
        "\n",
        "        orders_df=sqlContext.sql(\"select h.* from cshsshdr h where h.lhstatus in ('Complete', 'PO Generated', 'Tendered')\")\n",
        "        orders_df.createOrReplaceTempView('orders')\n",
        "\n",
        "        finalized_df=sqlContext.sql(\"select d.* from cshssdtl d inner join orders h on h.lhssordr = d.ldorder \"\n",
        "                                          \"where lditstat in ('Returned', 'Picked Up')\")\n",
        "        finalized_df.createOrReplaceTempView(\"finalized\")\n",
        "\n",
        "        ordered_df=sqlContext.sql(\"select d.* from cshssdtl d inner join orders h on h.lhssordr = d.ldorder left outer join finalized \"\n",
        "                             \" f on f.ldorder = d.ldorder and f.ldline  = d.ldline where d.lditstat in ('Ordered') and f.ldorder is null\")\n",
        "\n",
        "        combined_df=finalized_df.union(ordered_df)\n",
        "        combined_df.createOrReplaceTempView('combined')\n",
        "\n",
        "        print(\"query str1\")\n",
        "        query_str1 = \"\"\"select h.LHSTORE as STORE_NUMBER,                 \n",
        "                            lhpodate as TRANSACTION_DATE, \n",
        "        \t\t\t\t\tupper(trim(lhcustnm)) as CUSTOMER_NAME,\n",
        "        \t\t\t\t\tupper(trim(ldpart)) as MFG_PART_NUMBER,\n",
        "        \t\t\t\t\tupper(trim(lditmdesc)) as PART_DESCRIPTION,\n",
        "        \t\t\t\t\t'' as UPC,\n",
        "        \t\t\t\t\tlditmcost as COST,\n",
        "        \t\t\t\t\tlditmretl as SELL_PRICE,\n",
        "        \t\t\t\t\tcase when ldttype = 11 then lditmqty*-1 else lditmqty end as QUANTITY,\n",
        "        \t\t\t\t\t'' as UOM,\n",
        "        \t\t\t\t\tlhvndinv as INVOICE_NUMBER,\n",
        "        \t\t\t\t\tlhpssupp as VENDOR,        \t\t\t\t\t\n",
        "        \t\t\t\t\tcase when ldvyear=0 then NULL else ldvyear end as APPLICATION_YEAR,\n",
        "        \t\t\t\t\tupper(trim(ldvmodel)) as APPLICATION_MODEL,\n",
        "        \t\t\t\t\tupper(trim(ldvmake)) as APPLICATION_MAKE,\n",
        "        \t\t\t\t\tupper(trim(ldvengn)) as APPLICATION_ENGINE,\n",
        "        \t\t\t\t\tlditmcore as CORE_CHARGE,\n",
        "        \t\t\t\t\tlhpoprice as TOTAL_SALE,\n",
        "        \t\t\t\t\tlditmrsn as REASON_FOR_SALE,\n",
        "        \t\t\t\t\t'' as COMPETITOR_PRICE,\n",
        "        \t\t\t\t\tupper(trim(ldlabel)) as BRAND_NAME,\n",
        "        \t\t\t\t\tlhssordr as ORDER_NO,\n",
        "        \t\t\t\t\tupper(trim(lhsuppnm)) as VENDOR_NAME,\n",
        "        \t\t\t\t\t'' as TRANSACTION_TYPE,\n",
        "        \t\t\t\t\tldaltsku as SKU_NUMBER,\n",
        "        \t\t\t\t\tlditmretl as UNIT_RETAIL,\n",
        "        \t\t\t\t\tlditmcost as UNIT_COST,\n",
        "        \t\t\t\t\tcase when ldttype = 11 then lditmqty*-1 else lditmqty end as QUANTITY_SOLD,\n",
        "        \t\t\t\t\tlditmretl as EXTENDED_PRICE,\n",
        "        \t\t\t\t\tlditmcost as EXTENDED_COST,\n",
        "        \t\t\t\t\t'' as STATUS,\n",
        "        \t\t\t\t\t'' as PRICE_OVERRIDE,\n",
        "        \t\t\t\t\t'' as PRODUCT_CODE,\n",
        "        \t\t\t\t\t'' as REASON_TYPE_CODE,\n",
        "        \t\t\t\t\t'' as REASON_CODE,\n",
        "        \t\t\t\t\t'' as PRICING_CODE,\n",
        "        \t\t\t\t\t'' as STK_DLR_LINE_CODE,\n",
        "        \t\t\t\t\t'' as PRICING_CAMPAIGN,\n",
        "        \t\t\t\t\t'' as CAMPAIGN_EVENT,\n",
        "        \t\t\t\t\t'' as stripped_mfg_part_number,\n",
        "        \t\t\t\t\t'' as standard_brand_name,\n",
        "        \t\t\t\t\tcase when ldaapid='' then NULL else ldaapid end as mapped_sku_number,        \t\t\t\t\t\n",
        "        \t\t\t\t\t'' as standard_part_type,\n",
        "        \t\t\t\t\t'' as mapped_mfg_code,\n",
        "        \t\t\t\t\t'' as mapped_aaia_code\n",
        "        \t\t\t\tfrom combined d\n",
        "        \t\t\t\tinner join orders h on h.lhssordr = d.ldorder \"\"\"\n",
        "\n",
        "        temp_ss_second_source_stage_df=sqlContext.sql(query_str1)\n",
        "        temp_ss_second_source_stage_df.createOrReplaceTempView('temp_ss_second_source_stage')\n",
        "\n",
        "        print(\"query_str2\")\n",
        "        query_str2=\"\"\"  select\n",
        "                        cast(STORE_NUMBER as smallint) AS STORE_NUMBER,\n",
        "                        TRANSACTION_DATE,\n",
        "                        CUSTOMER_NAME,\n",
        "                        MFG_PART_NUMBER,\n",
        "                        PART_DESCRIPTION,\n",
        "                        UPC,\n",
        "                        COST,\n",
        "                        SELL_PRICE,\n",
        "                        QUANTITY,\n",
        "                        UOM,\n",
        "                        INVOICE_NUMBER,\n",
        "                        VENDOR,\n",
        "                        APPLICATION_YEAR,\n",
        "                        APPLICATION_MODEL,\n",
        "                        APPLICATION_MAKE,\n",
        "                        APPLICATION_ENGINE,\n",
        "                        CORE_CHARGE,\n",
        "                        TOTAL_SALE,\n",
        "                        REASON_FOR_SALE,\n",
        "                        COMPETITOR_PRICE,\n",
        "                        BRAND_NAME,\n",
        "                        ORDER_NO,\n",
        "                        VENDOR_NAME,\n",
        "                        TRANSACTION_TYPE,\n",
        "                        SKU_NUMBER,\n",
        "                        UNIT_RETAIL,\n",
        "                        UNIT_COST,\n",
        "                        case when QUANTITY_SOLD > 20 then 20 else QUANTITY_SOLD end as QUANTITY_SOLD,\n",
        "                        EXTENDED_PRICE,\n",
        "                        EXTENDED_COST,\n",
        "                        STATUS,\n",
        "                        PRICE_OVERRIDE,\n",
        "                        PRODUCT_CODE,\n",
        "                        REASON_TYPE_CODE,\n",
        "                        REASON_CODE,\n",
        "                        PRICING_CODE,\n",
        "                        STK_DLR_LINE_CODE,\n",
        "                        PRICING_CAMPAIGN,\n",
        "                        CAMPAIGN_EVENT,\n",
        "                        stripped_mfg_part_number,\n",
        "                        standard_brand_name,\n",
        "                        cast(mapped_sku_number as bigint) as MAPPED_SKU_NUMBER,\n",
        "                        standard_part_type,\n",
        "                        mapped_mfg_code,\n",
        "                        mapped_aaia_code\n",
        "                        from temp_ss_second_source_stage\n",
        "                        where TRANSACTION_DATE < (select min(ac.cal_date) as the_date\n",
        "                                                        from aap_calendar ac\n",
        "                                                             inner join \n",
        "                                                           (select cal_period, cal_year \n",
        "                                                                  from aap_calendar where cal_date = CURRENT_DATE) s\n",
        "                                                              on s.cal_period = ac.cal_period\n",
        "                                                                 and s.cal_year = ac.cal_year)\n",
        "                        \"\"\"\n",
        "\n",
        "        ss_second_source_stage_df = sqlContext.sql(query_str2)\n",
        "\n",
        "        print (\"******* Dataframe generated: ss_second_source_stage by code: second_sales.py *******\")\n",
        "        #ss_second_source_stage_df.show(10)\n",
        "\n",
        "        return ss_second_source_stage_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": [
        "%pyspark\n",
        "\n",
        "def get_period_calender():\n",
        "        print(\"get period calendar\")\n",
        "        aap_calendar = load_aap_calendar()\n",
        "        aap_calendar.createOrReplaceTempView(\"apc1\")\n",
        "        aap_period_calendar = sqlContext.sql(\"select dense_rank() over(order by cal_year,cal_period) as sequence_id ,t.* \"\n",
        "                                                   \"from (select  a.cal_year \\\n",
        "                                ,a.cal_period  \\\n",
        "                                ,min(a.cal_date) as start_date  \\\n",
        "                                ,max(a.cal_date) as end_date  \\\n",
        "                                from apc1 a  \\\n",
        "                                    group by a.cal_year, a.cal_period \\\n",
        "                                order by a.cal_year, a.cal_period) t\")\n",
        "        return aap_period_calendar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": [
        "%pyspark\n",
        "\n",
        "def get_period_id(val=0):\n",
        "        print(\"get period id\")\n",
        "        period_calendar=get_period_calender()\n",
        "        period_calendar.createOrReplaceTempView(\"apc\")\n",
        "\n",
        "        seq_val = sqlContext.sql(\"select max(sequence_id) from apc \\\n",
        "                                          where to_date(end_date) < CURRENT_DATE \")\n",
        "        seq_val = seq_val.rdd.flatMap(list).first()\n",
        "        seq_val = seq_val + val\n",
        "\n",
        "        return int(seq_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": [
        "%pyspark\n",
        "\n",
        "def ss_second_source():\n",
        "        print(\"ss second source\")\n",
        "        ss_second_source_stage_df=ss_second_source_stage()\n",
        "\n",
        "        ss_second_source_stage_df.createOrReplaceTempView('ss_second_source_stage')\n",
        "\n",
        "        df2 = sqlContext.sql(\"select * from ss_second_source_stage\")\n",
        "\n",
        "        df2.createOrReplaceTempView('combined_ss')\n",
        "\n",
        "        ss_second_source_df=sqlContext.sql(\n",
        "            \"select store_number,transaction_date,customer_name,mfg_part_number,part_description,upc,cost,sell_price,\"\n",
        "            \"quantity,uom,invoice_number,vendor,application_year,application_model,application_make,application_engine,\"\n",
        "            \"core_charge,total_sale,reason_for_sale,competitor_price,brand_name,order_no,vendor_name,transaction_type,\"\n",
        "            \"sku_number,unit_retail,unit_cost,quantity_sold,extended_price,extended_cost,status,price_override,\"\n",
        "            \"product_code,reason_type_code,reason_code,pricing_code,stk_dlr_line_code,pricing_campaign,campaign_event,\"\n",
        "            \"stripped_mfg_part_number,standard_brand_name,\"\n",
        "            \"case when mapped_sku_number=0 then NULL else mapped_sku_number end as mapped_sku_number,\"\n",
        "            \"standard_part_type,mapped_mfg_code,mapped_aaia_code \"\n",
        "            \"from combined_ss\")\n",
        "\n",
        "        print (\"******* Dataframe generated: ss_second_source by code: second_sales.py *******\")\n",
        "\n",
        "        return ss_second_source_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": [
        "%pyspark\n",
        "\n",
        "def ss_store_sku_totals():\n",
        "        print(\"ss store sku totals\")\n",
        "        ss_second_source_df=ss_second_source()\n",
        "        ss_second_source_df.createOrReplaceTempView(\"ss_second_source\")\n",
        "\n",
        "        aap_period_calendar_df=get_period_calender()\n",
        "        aap_period_calendar_df.createOrReplaceTempView(\"aap_period_calendar\")\n",
        "\n",
        "        get_period_id_0  = get_period_id(0)\n",
        "        get_period_id_12 = get_period_id(-12)\n",
        "        get_period_id_13 = get_period_id(-13)\n",
        "        get_period_id_25 = get_period_id(-25)\n",
        "        get_period_id_38 = get_period_id(-38)\n",
        "        get_period_id_26 = get_period_id(-26)\n",
        "        get_period_id_51 = get_period_id(-51)\n",
        "        get_period_id_39 = get_period_id(-39)\n",
        "\n",
        "        query_str=\"\"\"SELECT cast(t.store_number as smallint) as store_number\n",
        "                          ,cast(t.mapped_sku_number as bigint) AS sku_number \n",
        "                          ,SUM(CASE \n",
        "                                   WHEN a.sequence_id BETWEEN  %d   AND \n",
        "                                        %d  THEN \n",
        "                                    cast(t.quantity_sold as bigint)\n",
        "                                   ELSE \n",
        "                                    0 \n",
        "                               END) AS ss_sales \n",
        "                          ,SUM(CASE \n",
        "                                   WHEN a.sequence_id BETWEEN %d  AND \n",
        "                                        %d  THEN \n",
        "                                    cast(t.quantity_sold as bigint)\n",
        "                                   ELSE \n",
        "                                    0 \n",
        "                               END) AS ss_sales_py\n",
        "                          ,SUM(CASE \n",
        "                                   WHEN a.sequence_id BETWEEN  %d   AND \n",
        "                                        %d  THEN \n",
        "                                    cast(t.quantity_sold as bigint)\n",
        "                                   ELSE \n",
        "                                    0 \n",
        "                               END) AS ss_sales_ppy \n",
        "                          ,SUM(CASE \n",
        "                                   WHEN a.sequence_id BETWEEN %d  AND \n",
        "                                        %d  THEN \n",
        "                                    cast(t.quantity_sold as bigint)\n",
        "                                   ELSE \n",
        "                                    0 \n",
        "                               END) AS ss_sales_3py\n",
        "                      FROM ss_second_source t \n",
        "                     INNER JOIN aap_period_calendar a \n",
        "                        ON t.transaction_date BETWEEN a.start_date AND a.end_date \n",
        "                     WHERE t.mapped_sku_number IS NOT NULL \n",
        "                       AND a.sequence_id BETWEEN  %d  AND  %d \n",
        "                     GROUP BY t.store_number, t.mapped_sku_number \n",
        "                    HAVING SUM(t.quantity_sold) > 0 \"\"\" %(get_period_id_12,get_period_id_0,get_period_id_25,get_period_id_13, \n",
        "                                                          get_period_id_38,get_period_id_26,get_period_id_51,get_period_id_39,\n",
        "                                                          get_period_id_51,get_period_id_0)\n",
        "\n",
        "\n",
        "\n",
        "        ss_store_sku_totals_df=sqlContext.sql(query_str)\n",
        "        print (\"******* Dataframe generated: ss_store_sku_totals by code: second_sales.py *******\")\n",
        "        #ss_store_sku_totals_df.show(10)\n",
        "\n",
        "        return ss_store_sku_totals_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": [
        "%pyspark\n",
        "\n",
        "# Main\n",
        "#   Create data frame vio_store_sku_totals\n",
        "\n",
        "print(\"Start\")\n",
        "ss_second_source_stage_df= ss_second_source_stage()\n",
        "ss_second_source_df = ss_second_source()\n",
        "ss_store_sku_totals_df= ss_store_sku_totals()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": [
        "%pyspark\n",
        "\n",
        "from pyspark.sql.functions import col\n",
        "\n",
        "ss_store_sku_totals_df.filter(col(\"ss_sales_3py\")>0).show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": [
        "%pyspark\n",
        "ss_store_sku_totals_df.count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": [
        "%pyspark\n",
        "agg_store_sku_rolling.count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": [
        "%pyspark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": [
        "%pyspark\n",
        "df_final = agg_store_sku_rolling.join(ss_store_sku_totals_df, (agg_store_sku_rolling.csstor == ss_store_sku_totals_df.store_number) & (agg_store_sku_rolling.cssku == ss_store_sku_totals_df.sku_number), how='left')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": [
        "%pyspark\n",
        "df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": [
        "%pyspark\n",
        "df_final = df_final.filter(df_final.store_number.isNull())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": [
        "%pyspark\n",
        "df2.count()"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "format": "text/plain"
      },
      "source": [
        "%pyspark\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "language": "scala",
      "name": "spark2-scala"
    },
    "language_info": {
      "codemirror_mode": "text/x-scala",
      "file_extension": ".scala",
      "mimetype": "text/x-scala",
      "name": "scala",
      "pygments_lexer": "scala"
    },
    "name": "qty sold sales & SS Sales - 2 year forecast mhl"
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
